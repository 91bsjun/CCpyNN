{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "arctic-faith",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   num_of_li poly_anion chalcogen anion_1 anion_2  x_in_a  chal_in_a  x_in_c  \\\n",
      "0         24          P        Te      Te      Br    1.00       0.00    0.00   \n",
      "1         24          P        Te      Te      Br    0.75       0.25    0.25   \n",
      "2         24          P        Te      Te      Br    0.50       0.50    0.50   \n",
      "3         24          P        Te      Te      Br    0.50       0.50    0.50   \n",
      "4         24          P        Te      Te      Br    0.25       0.75    0.75   \n",
      "\n",
      "   chal_in_c  energy(ev)  ...  cage_size_x_in_a  cage_size_chal_in_a  \\\n",
      "0       1.00    -170.094  ...          2.857481             2.857481   \n",
      "1       0.75    -173.753  ...          2.856988             2.984879   \n",
      "2       0.50    -173.030  ...          2.827102             2.905770   \n",
      "3       0.50    -173.536  ...          2.807420             2.998073   \n",
      "4       0.25    -172.911  ...          2.667879             2.842302   \n",
      "\n",
      "   cage_size_x_in_c  cage_size_chal_in_c  std_cage_size  avg_cage_size  \\\n",
      "0          2.805444             2.805444       0.047045       2.831463   \n",
      "1          2.630549             2.842125       0.138414       2.828635   \n",
      "2          2.778769             2.862027       0.091540       2.843417   \n",
      "3          2.800983             2.803689       0.101039       2.852541   \n",
      "4          2.746878             2.936125       0.109450       2.798296   \n",
      "\n",
      "        volume  conductivity  conductivity_min  conductivity_max  \n",
      "0  1626.211750     72.535476         45.313786        116.110256  \n",
      "1  1588.348094    166.023829         92.497329        297.996838  \n",
      "2  1614.307261    518.590725        307.632354        874.213445  \n",
      "3  1522.146167     55.298032         28.131268        108.700125  \n",
      "4  1502.850690     72.311064         26.880566        194.523058  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"Data\\\\argyrodite\\\\Argyrodite_all_data.csv\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "protecting-programming",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     num_of_li  x_in_a  chal_in_a  x_in_c  chal_in_c  cage_size_x_in_a  \\\n",
      "111         28    0.00       1.00    1.00       0.00          2.555790   \n",
      "22          24    0.25       0.75    0.75       0.25          2.619974   \n",
      "96          28    0.50       0.50    0.50       0.50          2.717994   \n",
      "41          24    0.00       1.00    1.00       0.00          2.457198   \n",
      "45          28    0.00       1.00    0.00       1.00          2.727457   \n",
      "\n",
      "     cage_size_chal_in_a  cage_size_x_in_c  cage_size_chal_in_c  \\\n",
      "111             2.555790          2.750399             2.750399   \n",
      "22              2.646212          2.708633             2.651902   \n",
      "96              2.609908          2.574599             2.555008   \n",
      "41              2.457198          2.753352             2.753352   \n",
      "45              2.727457          2.787891             2.787891   \n",
      "\n",
      "     std_cage_size  avg_cage_size       volume  conductivity  \n",
      "111       0.097304       2.653095  1168.487026     46.272835  \n",
      "22        0.088750       2.656680  1204.459348     48.722685  \n",
      "96        0.062975       2.614377  1049.465381     64.875106  \n",
      "41        0.148077       2.605275  1061.757426      0.574705  \n",
      "45        0.030217       2.757674  1382.147418     31.883823  \n"
     ]
    }
   ],
   "source": [
    "core_data = df[['num_of_li', 'x_in_a', 'chal_in_a', 'x_in_c', 'chal_in_c', \n",
    "                'cage_size_x_in_a', 'cage_size_chal_in_a', 'cage_size_x_in_c', 'cage_size_chal_in_c',\n",
    "                'std_cage_size', 'avg_cage_size', 'volume', 'conductivity']]\n",
    "\n",
    "core_data = core_data.sample(frac=1)\n",
    "\n",
    "print(core_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "middle-german",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     count         mean         std         min          25%  \\\n",
      "num_of_li            169.0    25.958580    2.536296   20.000000    24.000000   \n",
      "x_in_a               169.0     0.523669    0.337668    0.000000     0.250000   \n",
      "chal_in_a            169.0     0.476331    0.337668    0.000000     0.250000   \n",
      "x_in_c               169.0     0.523669    0.337668    0.000000     0.250000   \n",
      "chal_in_c            169.0     0.476331    0.337668    0.000000     0.250000   \n",
      "cage_size_x_in_a     169.0     2.770734    0.158711    2.425287     2.654615   \n",
      "cage_size_chal_in_a  169.0     2.709242    0.170628    2.417616     2.566607   \n",
      "cage_size_x_in_c     169.0     2.730206    0.141882    2.405666     2.614744   \n",
      "cage_size_chal_in_c  169.0     2.650258    0.152311    2.405666     2.525840   \n",
      "std_cage_size        169.0     0.110328    0.067579    0.003134     0.057136   \n",
      "avg_cage_size        169.0     2.710402    0.100626    2.487849     2.646527   \n",
      "volume               169.0  1240.221590  202.776395  970.276915  1086.160202   \n",
      "\n",
      "                             50%          75%          max  \n",
      "num_of_li              28.000000    28.000000    29.000000  \n",
      "x_in_a                  0.500000     0.750000     1.000000  \n",
      "chal_in_a               0.500000     0.750000     1.000000  \n",
      "x_in_c                  0.500000     0.750000     1.000000  \n",
      "chal_in_c               0.500000     0.750000     1.000000  \n",
      "cage_size_x_in_a        2.760836     2.889026     3.104778  \n",
      "cage_size_chal_in_a     2.666600     2.855320     3.120808  \n",
      "cage_size_x_in_c        2.735947     2.812260     3.086349  \n",
      "cage_size_chal_in_c     2.626109     2.775839     2.995685  \n",
      "std_cage_size           0.094420     0.155112     0.261775  \n",
      "avg_cage_size           2.696994     2.764041     2.995263  \n",
      "volume               1192.199508  1341.509078  1835.284808  \n"
     ]
    }
   ],
   "source": [
    "x_stats = core_data.describe()\n",
    "x_stats.pop(\"conductivity\")\n",
    "x_stats = x_stats.transpose()\n",
    "print(x_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "outstanding-valuable",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     num_of_li  x_in_a  chal_in_a  x_in_c  chal_in_c  cage_size_x_in_a  \\\n",
      "111         28    0.00       1.00    1.00       0.00          2.555790   \n",
      "22          24    0.25       0.75    0.75       0.25          2.619974   \n",
      "96          28    0.50       0.50    0.50       0.50          2.717994   \n",
      "41          24    0.00       1.00    1.00       0.00          2.457198   \n",
      "45          28    0.00       1.00    0.00       1.00          2.727457   \n",
      "\n",
      "     cage_size_chal_in_a  cage_size_x_in_c  cage_size_chal_in_c  \\\n",
      "111             2.555790          2.750399             2.750399   \n",
      "22              2.646212          2.708633             2.651902   \n",
      "96              2.609908          2.574599             2.555008   \n",
      "41              2.457198          2.753352             2.753352   \n",
      "45              2.727457          2.787891             2.787891   \n",
      "\n",
      "     std_cage_size  avg_cage_size       volume  \n",
      "111       0.097304       2.653095  1168.487026  \n",
      "22        0.088750       2.656680  1204.459348  \n",
      "96        0.062975       2.614377  1049.465381  \n",
      "41        0.148077       2.605275  1061.757426  \n",
      "45        0.030217       2.757674  1382.147418  \n",
      "111    46.272835\n",
      "22     48.722685\n",
      "96     64.875106\n",
      "41      0.574705\n",
      "45     31.883823\n",
      "Name: conductivity, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "y = core_data.pop(\"conductivity\")\n",
    "X = core_data.copy()\n",
    "print(X.head())\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "neural-rebecca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     num_of_li    x_in_a  chal_in_a    x_in_c  chal_in_c  cage_size_x_in_a  \\\n",
      "111   0.804882 -1.550838   1.550838  1.410649  -1.410649         -1.354314   \n",
      "22   -0.772221 -0.810466   0.810466  0.670277  -0.670277         -0.949903   \n",
      "96    0.804882 -0.070094   0.070094 -0.070094   0.070094         -0.332304   \n",
      "41   -0.772221 -1.550838   1.550838  1.410649  -1.410649         -1.975524   \n",
      "45    0.804882 -1.550838   1.550838 -1.550838   1.550838         -0.272680   \n",
      "\n",
      "     cage_size_chal_in_a  cage_size_x_in_c  cage_size_chal_in_c  \\\n",
      "111            -0.899333          0.142324             0.657481   \n",
      "22             -0.369399         -0.152049             0.010798   \n",
      "96             -0.582165         -1.096729            -0.625362   \n",
      "41             -1.477154          0.163133             0.676865   \n",
      "45              0.106753          0.406567             0.903631   \n",
      "\n",
      "     std_cage_size  avg_cage_size    volume  \n",
      "111      -0.192718      -0.569510 -0.353762  \n",
      "22       -0.319307      -0.533876 -0.176363  \n",
      "96       -0.700711      -0.954274 -0.940722  \n",
      "41        0.558594      -1.044735 -0.880103  \n",
      "45       -1.185453       0.469773  0.699913  \n"
     ]
    }
   ],
   "source": [
    "def norm(x):\n",
    "  return (x - x_stats['mean']) / x_stats['std']\n",
    "\n",
    "normed_X = norm(X)\n",
    "print(normed_X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "different-campaign",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 135 samples, validate on 34 samples\n",
      "Epoch 1/1000\n",
      "135/135 [==============================] - 0s 3ms/sample - loss: 6789.7933 - mse: 6789.7930 - val_loss: 18619.6811 - val_mse: 18619.6797\n",
      "Epoch 2/1000\n",
      "135/135 [==============================] - 0s 216us/sample - loss: 6683.2917 - mse: 6683.2915 - val_loss: 18500.4688 - val_mse: 18500.4688\n",
      "Epoch 3/1000\n",
      "135/135 [==============================] - 0s 214us/sample - loss: 6595.2924 - mse: 6595.2925 - val_loss: 18384.0119 - val_mse: 18384.0117\n",
      "Epoch 4/1000\n",
      "135/135 [==============================] - 0s 195us/sample - loss: 6503.2302 - mse: 6503.2305 - val_loss: 18219.6774 - val_mse: 18219.6758\n",
      "Epoch 5/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 6398.7235 - mse: 6398.7241 - val_loss: 18077.4090 - val_mse: 18077.4082\n",
      "Epoch 6/1000\n",
      "135/135 [==============================] - 0s 216us/sample - loss: 6296.3385 - mse: 6296.3389 - val_loss: 17924.4200 - val_mse: 17924.4199\n",
      "Epoch 7/1000\n",
      "135/135 [==============================] - 0s 214us/sample - loss: 6187.1242 - mse: 6187.1240 - val_loss: 17764.5919 - val_mse: 17764.5918\n",
      "Epoch 8/1000\n",
      "135/135 [==============================] - 0s 214us/sample - loss: 6074.8166 - mse: 6074.8169 - val_loss: 17581.0570 - val_mse: 17581.0566\n",
      "Epoch 9/1000\n",
      "135/135 [==============================] - 0s 231us/sample - loss: 5945.6345 - mse: 5945.6343 - val_loss: 17392.4200 - val_mse: 17392.4199\n",
      "Epoch 10/1000\n",
      "135/135 [==============================] - 0s 233us/sample - loss: 5813.9641 - mse: 5813.9639 - val_loss: 17132.9908 - val_mse: 17132.9902\n",
      "Epoch 11/1000\n",
      "135/135 [==============================] - 0s 226us/sample - loss: 5658.5514 - mse: 5658.5513 - val_loss: 16918.2785 - val_mse: 16918.2793\n",
      "Epoch 12/1000\n",
      "135/135 [==============================] - 0s 229us/sample - loss: 5520.6513 - mse: 5520.6514 - val_loss: 16690.2178 - val_mse: 16690.2168\n",
      "Epoch 13/1000\n",
      "135/135 [==============================] - 0s 229us/sample - loss: 5370.7734 - mse: 5370.7734 - val_loss: 16446.8750 - val_mse: 16446.8750\n",
      "Epoch 14/1000\n",
      "135/135 [==============================] - 0s 222us/sample - loss: 5218.8934 - mse: 5218.8931 - val_loss: 16153.4577 - val_mse: 16153.4580\n",
      "Epoch 15/1000\n",
      "135/135 [==============================] - 0s 222us/sample - loss: 5056.2540 - mse: 5056.2544 - val_loss: 15915.4858 - val_mse: 15915.4854\n",
      "Epoch 16/1000\n",
      "135/135 [==============================] - 0s 236us/sample - loss: 4905.4326 - mse: 4905.4331 - val_loss: 15661.3952 - val_mse: 15661.3955\n",
      "Epoch 17/1000\n",
      "135/135 [==============================] - 0s 251us/sample - loss: 4762.1094 - mse: 4762.1094 - val_loss: 15356.8015 - val_mse: 15356.8018\n",
      "Epoch 18/1000\n",
      "135/135 [==============================] - 0s 222us/sample - loss: 4592.6120 - mse: 4592.6118 - val_loss: 15076.9246 - val_mse: 15076.9248\n",
      "Epoch 19/1000\n",
      "135/135 [==============================] - 0s 325us/sample - loss: 4434.6416 - mse: 4434.6416 - val_loss: 14770.4706 - val_mse: 14770.4707\n",
      "Epoch 20/1000\n",
      "135/135 [==============================] - 0s 347us/sample - loss: 4266.6775 - mse: 4266.6772 - val_loss: 14477.0450 - val_mse: 14477.0449\n",
      "Epoch 21/1000\n",
      "135/135 [==============================] - 0s 251us/sample - loss: 4098.9146 - mse: 4098.9150 - val_loss: 14168.5418 - val_mse: 14168.5420\n",
      "Epoch 22/1000\n",
      "135/135 [==============================] - 0s 259us/sample - loss: 3953.4311 - mse: 3953.4309 - val_loss: 13871.0404 - val_mse: 13871.0400\n",
      "Epoch 23/1000\n",
      "135/135 [==============================] - 0s 214us/sample - loss: 3796.5959 - mse: 3796.5959 - val_loss: 13595.0267 - val_mse: 13595.0264\n",
      "Epoch 24/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 3674.0048 - mse: 3674.0046 - val_loss: 13279.2794 - val_mse: 13279.2793\n",
      "Epoch 25/1000\n",
      "135/135 [==============================] - 0s 222us/sample - loss: 3537.7121 - mse: 3537.7122 - val_loss: 12967.9435 - val_mse: 12967.9434\n",
      "Epoch 26/1000\n",
      "135/135 [==============================] - 0s 222us/sample - loss: 3402.2108 - mse: 3402.2109 - val_loss: 12678.8483 - val_mse: 12678.8486\n",
      "Epoch 27/1000\n",
      "135/135 [==============================] - 0s 214us/sample - loss: 3283.9378 - mse: 3283.9377 - val_loss: 12421.7960 - val_mse: 12421.7959\n",
      "Epoch 28/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 3176.2428 - mse: 3176.2429 - val_loss: 12183.0584 - val_mse: 12183.0586\n",
      "Epoch 29/1000\n",
      "135/135 [==============================] - 0s 222us/sample - loss: 3077.4440 - mse: 3077.4441 - val_loss: 11898.8171 - val_mse: 11898.8174\n",
      "Epoch 30/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 2987.5162 - mse: 2987.5159 - val_loss: 11726.7063 - val_mse: 11726.7061\n",
      "Epoch 31/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 2918.2754 - mse: 2918.2754 - val_loss: 11575.0919 - val_mse: 11575.0918\n",
      "Epoch 32/1000\n",
      "135/135 [==============================] - 0s 155us/sample - loss: 2872.7191 - mse: 2872.7192 - val_loss: 11336.1112 - val_mse: 11336.1113\n",
      "Epoch 33/1000\n",
      "135/135 [==============================] - 0s 176us/sample - loss: 2806.1690 - mse: 2806.1689 - val_loss: 11155.0184 - val_mse: 11155.0186\n",
      "Epoch 34/1000\n",
      "135/135 [==============================] - 0s 162us/sample - loss: 2749.8342 - mse: 2749.8342 - val_loss: 11112.0694 - val_mse: 11112.0703\n",
      "Epoch 35/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 2716.9480 - mse: 2716.9480 - val_loss: 10928.2606 - val_mse: 10928.2607\n",
      "Epoch 36/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 2680.4438 - mse: 2680.4441 - val_loss: 10844.9246 - val_mse: 10844.9248\n",
      "Epoch 37/1000\n",
      "135/135 [==============================] - 0s 163us/sample - loss: 2649.9192 - mse: 2649.9189 - val_loss: 10722.9991 - val_mse: 10722.9990\n",
      "Epoch 38/1000\n",
      "135/135 [==============================] - 0s 163us/sample - loss: 2616.8907 - mse: 2616.8906 - val_loss: 10642.4067 - val_mse: 10642.4062\n",
      "Epoch 39/1000\n",
      "135/135 [==============================] - 0s 155us/sample - loss: 2604.5443 - mse: 2604.5442 - val_loss: 10566.7610 - val_mse: 10566.7607\n",
      "Epoch 40/1000\n",
      "135/135 [==============================] - 0s 162us/sample - loss: 2577.9023 - mse: 2577.9023 - val_loss: 10463.4743 - val_mse: 10463.4746\n",
      "Epoch 41/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 2556.7962 - mse: 2556.7964 - val_loss: 10396.2670 - val_mse: 10396.2666\n",
      "Epoch 42/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 2539.1700 - mse: 2539.1699 - val_loss: 10277.4646 - val_mse: 10277.4648\n",
      "Epoch 43/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 2522.2076 - mse: 2522.2078 - val_loss: 10211.5409 - val_mse: 10211.5400\n",
      "Epoch 44/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 2512.0025 - mse: 2512.0022 - val_loss: 10107.1112 - val_mse: 10107.1113\n",
      "Epoch 45/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 2496.6437 - mse: 2496.6436 - val_loss: 10015.7155 - val_mse: 10015.7148\n",
      "Epoch 46/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 2482.6852 - mse: 2482.6853 - val_loss: 10059.5354 - val_mse: 10059.5352\n",
      "Epoch 47/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 2474.3226 - mse: 2474.3225 - val_loss: 10016.2541 - val_mse: 10016.2539\n",
      "Epoch 48/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 2466.7875 - mse: 2466.7876 - val_loss: 10017.2362 - val_mse: 10017.2363\n",
      "Epoch 49/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 2451.7116 - mse: 2451.7119 - val_loss: 9988.0487 - val_mse: 9988.0488\n",
      "Epoch 50/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 2436.1998 - mse: 2436.1997 - val_loss: 9987.0179 - val_mse: 9987.0186\n",
      "Epoch 51/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 2436.5050 - mse: 2436.5049 - val_loss: 10074.0827 - val_mse: 10074.0830\n",
      "Epoch 52/1000\n",
      "135/135 [==============================] - 0s 184us/sample - loss: 2419.2278 - mse: 2419.2278 - val_loss: 10053.1746 - val_mse: 10053.1748\n",
      "Epoch 53/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 2407.4078 - mse: 2407.4080 - val_loss: 10030.0312 - val_mse: 10030.0312\n",
      "Epoch 54/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 2402.6244 - mse: 2402.6243 - val_loss: 10135.6218 - val_mse: 10135.6211\n",
      "Epoch 55/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 2391.6677 - mse: 2391.6675 - val_loss: 10124.9233 - val_mse: 10124.9229\n",
      "Epoch 56/1000\n",
      "135/135 [==============================] - 0s 155us/sample - loss: 2388.7412 - mse: 2388.7412 - val_loss: 10082.2224 - val_mse: 10082.2227\n",
      "Epoch 57/1000\n",
      "135/135 [==============================] - 0s 155us/sample - loss: 2375.4811 - mse: 2375.4810 - val_loss: 10003.5271 - val_mse: 10003.5273\n",
      "Epoch 58/1000\n",
      "135/135 [==============================] - 0s 155us/sample - loss: 2367.5404 - mse: 2367.5405 - val_loss: 10016.5735 - val_mse: 10016.5732\n",
      "Epoch 59/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 2365.3089 - mse: 2365.3091 - val_loss: 9967.1020 - val_mse: 9967.1016\n",
      "Epoch 60/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 2355.7551 - mse: 2355.7551 - val_loss: 9986.1172 - val_mse: 9986.1172\n",
      "Epoch 61/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 2343.4088 - mse: 2343.4087 - val_loss: 9939.5193 - val_mse: 9939.5195\n",
      "Epoch 62/1000\n",
      "135/135 [==============================] - 0s 184us/sample - loss: 2333.7605 - mse: 2333.7607 - val_loss: 9923.5689 - val_mse: 9923.5693\n",
      "Epoch 63/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 2327.8194 - mse: 2327.8193 - val_loss: 9961.5303 - val_mse: 9961.5303\n",
      "Epoch 64/1000\n",
      "135/135 [==============================] - 0s 176us/sample - loss: 2322.8671 - mse: 2322.8669 - val_loss: 10061.5767 - val_mse: 10061.5771\n",
      "Epoch 65/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 2316.0162 - mse: 2316.0161 - val_loss: 10063.4756 - val_mse: 10063.4766\n",
      "Epoch 66/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 2316.5423 - mse: 2316.5425 - val_loss: 10087.3819 - val_mse: 10087.3828\n",
      "Epoch 67/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 2304.2297 - mse: 2304.2297 - val_loss: 9972.2500 - val_mse: 9972.2500\n",
      "Epoch 68/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 2295.5639 - mse: 2295.5642 - val_loss: 9964.4334 - val_mse: 9964.4336\n",
      "Epoch 69/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 2289.8435 - mse: 2289.8435 - val_loss: 9948.4706 - val_mse: 9948.4707\n",
      "Epoch 70/1000\n",
      "135/135 [==============================] - 0s 188us/sample - loss: 2285.7403 - mse: 2285.7405 - val_loss: 9984.9003 - val_mse: 9984.9004\n",
      "Epoch 71/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 2290.0784 - mse: 2290.0781 - val_loss: 9996.8824 - val_mse: 9996.8828\n",
      "Epoch 72/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 2276.2704 - mse: 2276.2703 - val_loss: 9900.8598 - val_mse: 9900.8604\n",
      "Epoch 73/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 2265.3075 - mse: 2265.3074 - val_loss: 9977.5574 - val_mse: 9977.5566\n",
      "Epoch 74/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 2270.0468 - mse: 2270.0469 - val_loss: 9887.7321 - val_mse: 9887.7314\n",
      "Epoch 75/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 2257.3474 - mse: 2257.3474 - val_loss: 9890.3258 - val_mse: 9890.3252\n",
      "Epoch 76/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 2251.6950 - mse: 2251.6951 - val_loss: 9922.6356 - val_mse: 9922.6357\n",
      "Epoch 77/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 2253.6600 - mse: 2253.6599 - val_loss: 9979.7555 - val_mse: 9979.7559\n",
      "Epoch 78/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 2244.2237 - mse: 2244.2236 - val_loss: 9972.3134 - val_mse: 9972.3135\n",
      "Epoch 79/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 2242.8190 - mse: 2242.8191 - val_loss: 9985.5455 - val_mse: 9985.5459\n",
      "Epoch 80/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 2240.2664 - mse: 2240.2664 - val_loss: 10038.8336 - val_mse: 10038.8340\n",
      "Epoch 81/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 2240.5558 - mse: 2240.5557 - val_loss: 10085.4540 - val_mse: 10085.4541\n",
      "Epoch 82/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 2233.0015 - mse: 2233.0017 - val_loss: 9971.6144 - val_mse: 9971.6143\n",
      "Epoch 83/1000\n",
      "135/135 [==============================] - 0s 171us/sample - loss: 2222.3444 - mse: 2222.3445 - val_loss: 9876.8222 - val_mse: 9876.8213\n",
      "Epoch 84/1000\n",
      "135/135 [==============================] - 0s 184us/sample - loss: 2218.7335 - mse: 2218.7336 - val_loss: 9833.3244 - val_mse: 9833.3242\n",
      "Epoch 85/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 2218.7241 - mse: 2218.7241 - val_loss: 9835.6002 - val_mse: 9835.6006\n",
      "Epoch 86/1000\n",
      "135/135 [==============================] - 0s 178us/sample - loss: 2211.9187 - mse: 2211.9187 - val_loss: 9845.9306 - val_mse: 9845.9297\n",
      "Epoch 87/1000\n",
      "135/135 [==============================] - 0s 163us/sample - loss: 2206.4753 - mse: 2206.4753 - val_loss: 9856.3658 - val_mse: 9856.3662\n",
      "Epoch 88/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 2204.0297 - mse: 2204.0295 - val_loss: 9891.4159 - val_mse: 9891.4150\n",
      "Epoch 89/1000\n",
      "135/135 [==============================] - 0s 167us/sample - loss: 2196.6617 - mse: 2196.6619 - val_loss: 9859.1792 - val_mse: 9859.1797\n",
      "Epoch 90/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 2197.6774 - mse: 2197.6772 - val_loss: 9853.2454 - val_mse: 9853.2451\n",
      "Epoch 91/1000\n",
      "135/135 [==============================] - 0s 184us/sample - loss: 2192.6709 - mse: 2192.6709 - val_loss: 9957.5859 - val_mse: 9957.5859\n",
      "Epoch 92/1000\n",
      "135/135 [==============================] - 0s 169us/sample - loss: 2184.3695 - mse: 2184.3694 - val_loss: 9860.3814 - val_mse: 9860.3818\n",
      "Epoch 93/1000\n",
      "135/135 [==============================] - 0s 155us/sample - loss: 2180.6990 - mse: 2180.6990 - val_loss: 9865.0124 - val_mse: 9865.0127\n",
      "Epoch 94/1000\n",
      "135/135 [==============================] - 0s 200us/sample - loss: 2188.4733 - mse: 2188.4734 - val_loss: 9906.7744 - val_mse: 9906.7734\n",
      "Epoch 95/1000\n",
      "135/135 [==============================] - 0s 229us/sample - loss: 2175.5753 - mse: 2175.5752 - val_loss: 9844.5832 - val_mse: 9844.5830\n",
      "Epoch 96/1000\n",
      "135/135 [==============================] - 0s 214us/sample - loss: 2178.6533 - mse: 2178.6533 - val_loss: 9950.2996 - val_mse: 9950.2998\n",
      "Epoch 97/1000\n",
      "135/135 [==============================] - 0s 214us/sample - loss: 2166.4947 - mse: 2166.4946 - val_loss: 10020.4164 - val_mse: 10020.4160\n",
      "Epoch 98/1000\n",
      "135/135 [==============================] - 0s 214us/sample - loss: 2164.4520 - mse: 2164.4521 - val_loss: 10009.7431 - val_mse: 10009.7422\n",
      "Epoch 99/1000\n",
      "135/135 [==============================] - 0s 259us/sample - loss: 2163.9660 - mse: 2163.9661 - val_loss: 9929.8497 - val_mse: 9929.8496\n",
      "Epoch 100/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 2155.0291 - mse: 2155.0291 - val_loss: 9956.2978 - val_mse: 9956.2979\n",
      "Epoch 101/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 2153.3944 - mse: 2153.3945 - val_loss: 9881.6176 - val_mse: 9881.6172\n",
      "Epoch 102/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 2151.2294 - mse: 2151.2295 - val_loss: 9892.6654 - val_mse: 9892.6650\n",
      "Epoch 103/1000\n",
      "135/135 [==============================] - 0s 162us/sample - loss: 2142.4989 - mse: 2142.4990 - val_loss: 9894.8323 - val_mse: 9894.8330\n",
      "Epoch 104/1000\n",
      "135/135 [==============================] - 0s 163us/sample - loss: 2145.5214 - mse: 2145.5212 - val_loss: 9917.0685 - val_mse: 9917.0684\n",
      "Epoch 105/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 2154.6761 - mse: 2154.6763 - val_loss: 9905.3874 - val_mse: 9905.3877\n",
      "Epoch 106/1000\n",
      "135/135 [==============================] - 0s 163us/sample - loss: 2133.6601 - mse: 2133.6602 - val_loss: 9897.8741 - val_mse: 9897.8740\n",
      "Epoch 107/1000\n",
      "135/135 [==============================] - 0s 178us/sample - loss: 2134.6706 - mse: 2134.6704 - val_loss: 9915.0097 - val_mse: 9915.0088\n",
      "Epoch 108/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 0s 192us/sample - loss: 2136.8511 - mse: 2136.8511 - val_loss: 9956.9779 - val_mse: 9956.9775\n",
      "Epoch 109/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 2131.3504 - mse: 2131.3503 - val_loss: 10002.7004 - val_mse: 10002.7002\n",
      "Epoch 110/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 2121.2375 - mse: 2121.2375 - val_loss: 9933.8350 - val_mse: 9933.8350\n",
      "Epoch 111/1000\n",
      "135/135 [==============================] - 0s 163us/sample - loss: 2118.1229 - mse: 2118.1228 - val_loss: 9944.0119 - val_mse: 9944.0117\n",
      "Epoch 112/1000\n",
      "135/135 [==============================] - 0s 163us/sample - loss: 2118.0420 - mse: 2118.0422 - val_loss: 9913.2238 - val_mse: 9913.2246\n",
      "Epoch 113/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 2112.9188 - mse: 2112.9187 - val_loss: 9929.9591 - val_mse: 9929.9600\n",
      "Epoch 114/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 2110.1341 - mse: 2110.1340 - val_loss: 9948.9945 - val_mse: 9948.9941\n",
      "Epoch 115/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 2108.8602 - mse: 2108.8601 - val_loss: 9945.4628 - val_mse: 9945.4629\n",
      "Epoch 116/1000\n",
      "135/135 [==============================] - 0s 178us/sample - loss: 2103.9947 - mse: 2103.9946 - val_loss: 9919.7955 - val_mse: 9919.7959\n",
      "Epoch 117/1000\n",
      "135/135 [==============================] - 0s 168us/sample - loss: 2108.2350 - mse: 2108.2349 - val_loss: 9861.8911 - val_mse: 9861.8916\n",
      "Epoch 118/1000\n",
      "135/135 [==============================] - 0s 178us/sample - loss: 2099.6420 - mse: 2099.6418 - val_loss: 9937.5322 - val_mse: 9937.5322\n",
      "Epoch 119/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 2094.0306 - mse: 2094.0308 - val_loss: 9943.2891 - val_mse: 9943.2891\n",
      "Epoch 120/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 2091.2592 - mse: 2091.2593 - val_loss: 10037.8355 - val_mse: 10037.8359\n",
      "Epoch 121/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 2083.0194 - mse: 2083.0195 - val_loss: 10033.2721 - val_mse: 10033.2725\n",
      "Epoch 122/1000\n",
      "135/135 [==============================] - 0s 163us/sample - loss: 2087.7994 - mse: 2087.7993 - val_loss: 9953.3548 - val_mse: 9953.3545\n",
      "Epoch 123/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 2084.3845 - mse: 2084.3845 - val_loss: 9955.2054 - val_mse: 9955.2061\n",
      "Epoch 124/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 2077.7080 - mse: 2077.7080 - val_loss: 9968.0032 - val_mse: 9968.0039\n",
      "Epoch 125/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 2078.5786 - mse: 2078.5784 - val_loss: 10042.0290 - val_mse: 10042.0293\n",
      "Epoch 126/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 2069.3056 - mse: 2069.3059 - val_loss: 10034.6098 - val_mse: 10034.6104\n",
      "Epoch 127/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 2064.2388 - mse: 2064.2388 - val_loss: 10040.4072 - val_mse: 10040.4072\n",
      "Epoch 128/1000\n",
      "135/135 [==============================] - 0s 229us/sample - loss: 2063.4889 - mse: 2063.4888 - val_loss: 9948.3773 - val_mse: 9948.3770\n",
      "Epoch 129/1000\n",
      "135/135 [==============================] - 0s 214us/sample - loss: 2062.8922 - mse: 2062.8921 - val_loss: 9964.4012 - val_mse: 9964.4004\n",
      "Epoch 130/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 2059.4024 - mse: 2059.4026 - val_loss: 9962.5689 - val_mse: 9962.5693\n",
      "Epoch 131/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 2065.1965 - mse: 2065.1965 - val_loss: 9926.3405 - val_mse: 9926.3398\n",
      "Epoch 132/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 2049.2830 - mse: 2049.2832 - val_loss: 9840.2771 - val_mse: 9840.2773\n",
      "Epoch 133/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 2051.4653 - mse: 2051.4653 - val_loss: 9932.8313 - val_mse: 9932.8311\n",
      "Epoch 134/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 2050.9683 - mse: 2050.9683 - val_loss: 9850.7583 - val_mse: 9850.7578\n",
      "Epoch 135/1000\n",
      "135/135 [==============================] - 0s 195us/sample - loss: 2043.5707 - mse: 2043.5708 - val_loss: 9939.3157 - val_mse: 9939.3164\n",
      "Epoch 136/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 2039.8887 - mse: 2039.8889 - val_loss: 9934.4228 - val_mse: 9934.4229\n",
      "Epoch 137/1000\n",
      "135/135 [==============================] - 0s 222us/sample - loss: 2032.4336 - mse: 2032.4336 - val_loss: 9935.2491 - val_mse: 9935.2490\n",
      "Epoch 138/1000\n",
      "135/135 [==============================] - 0s 222us/sample - loss: 2036.6684 - mse: 2036.6686 - val_loss: 9867.8433 - val_mse: 9867.8438\n",
      "Epoch 139/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 2038.3135 - mse: 2038.3136 - val_loss: 9883.8056 - val_mse: 9883.8047\n",
      "Epoch 140/1000\n",
      "135/135 [==============================] - 0s 162us/sample - loss: 2029.4799 - mse: 2029.4799 - val_loss: 9910.2270 - val_mse: 9910.2266\n",
      "Epoch 141/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 2027.2344 - mse: 2027.2345 - val_loss: 9984.5377 - val_mse: 9984.5381\n",
      "Epoch 142/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 2023.9467 - mse: 2023.9468 - val_loss: 10046.6792 - val_mse: 10046.6797\n",
      "Epoch 143/1000\n",
      "135/135 [==============================] - 0s 222us/sample - loss: 2018.0092 - mse: 2018.0090 - val_loss: 10084.4839 - val_mse: 10084.4834\n",
      "Epoch 144/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 2017.0777 - mse: 2017.0775 - val_loss: 10008.0303 - val_mse: 10008.0303\n",
      "Epoch 145/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 2016.9884 - mse: 2016.9884 - val_loss: 9969.7955 - val_mse: 9969.7959\n",
      "Epoch 146/1000\n",
      "135/135 [==============================] - 0s 222us/sample - loss: 2006.7684 - mse: 2006.7683 - val_loss: 9980.6567 - val_mse: 9980.6562\n",
      "Epoch 147/1000\n",
      "135/135 [==============================] - 0s 222us/sample - loss: 2004.8404 - mse: 2004.8405 - val_loss: 9982.9568 - val_mse: 9982.9570\n",
      "Epoch 148/1000\n",
      "135/135 [==============================] - 0s 222us/sample - loss: 2001.7805 - mse: 2001.7805 - val_loss: 9971.4559 - val_mse: 9971.4561\n",
      "Epoch 149/1000\n",
      "135/135 [==============================] - 0s 214us/sample - loss: 2001.0901 - mse: 2001.0901 - val_loss: 9887.7436 - val_mse: 9887.7432\n",
      "Epoch 150/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 1999.6027 - mse: 1999.6025 - val_loss: 9953.5786 - val_mse: 9953.5791\n",
      "Epoch 151/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 1995.9901 - mse: 1995.9902 - val_loss: 10000.8929 - val_mse: 10000.8936\n",
      "Epoch 152/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 1992.1437 - mse: 1992.1438 - val_loss: 9954.4329 - val_mse: 9954.4326\n",
      "Epoch 153/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 1982.8722 - mse: 1982.8722 - val_loss: 9907.7036 - val_mse: 9907.7041\n",
      "Epoch 154/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 1981.8192 - mse: 1981.8192 - val_loss: 10012.8341 - val_mse: 10012.8350\n",
      "Epoch 155/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 1980.6073 - mse: 1980.6074 - val_loss: 9976.8676 - val_mse: 9976.8672\n",
      "Epoch 156/1000\n",
      "135/135 [==============================] - 0s 214us/sample - loss: 1972.1890 - mse: 1972.1891 - val_loss: 9947.2013 - val_mse: 9947.2012\n",
      "Epoch 157/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 1973.9507 - mse: 1973.9507 - val_loss: 9855.5161 - val_mse: 9855.5166\n",
      "Epoch 158/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 1969.2818 - mse: 1969.2817 - val_loss: 9970.1884 - val_mse: 9970.1885\n",
      "Epoch 159/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 1960.8411 - mse: 1960.8412 - val_loss: 9913.1461 - val_mse: 9913.1465\n",
      "Epoch 160/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 1959.9934 - mse: 1959.9933 - val_loss: 9959.6301 - val_mse: 9959.6309\n",
      "Epoch 161/1000\n",
      "135/135 [==============================] - 0s 214us/sample - loss: 1960.3688 - mse: 1960.3688 - val_loss: 9855.9651 - val_mse: 9855.9648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 162/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 1955.1752 - mse: 1955.1752 - val_loss: 9933.6921 - val_mse: 9933.6924\n",
      "Epoch 163/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 1950.0659 - mse: 1950.0659 - val_loss: 9974.4972 - val_mse: 9974.4971\n",
      "Epoch 164/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 1948.8035 - mse: 1948.8035 - val_loss: 10029.9802 - val_mse: 10029.9795\n",
      "Epoch 165/1000\n",
      "135/135 [==============================] - 0s 155us/sample - loss: 1945.1779 - mse: 1945.1777 - val_loss: 10054.4766 - val_mse: 10054.4766\n",
      "Epoch 166/1000\n",
      "135/135 [==============================] - 0s 163us/sample - loss: 1940.6524 - mse: 1940.6523 - val_loss: 9991.3566 - val_mse: 9991.3564\n",
      "Epoch 167/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 1940.7890 - mse: 1940.7889 - val_loss: 10008.1425 - val_mse: 10008.1426\n",
      "Epoch 168/1000\n",
      "135/135 [==============================] - 0s 173us/sample - loss: 1936.2132 - mse: 1936.2133 - val_loss: 10013.6990 - val_mse: 10013.6982\n",
      "Epoch 169/1000\n",
      "135/135 [==============================] - 0s 266us/sample - loss: 1933.9746 - mse: 1933.9746 - val_loss: 10054.6714 - val_mse: 10054.6709\n",
      "Epoch 170/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 1925.2578 - mse: 1925.2578 - val_loss: 10068.6039 - val_mse: 10068.6035\n",
      "Epoch 171/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 1929.8489 - mse: 1929.8489 - val_loss: 10129.4472 - val_mse: 10129.4463\n",
      "Epoch 172/1000\n",
      "135/135 [==============================] - 0s 163us/sample - loss: 1927.7800 - mse: 1927.7800 - val_loss: 10123.7220 - val_mse: 10123.7227\n",
      "Epoch 173/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 1923.4982 - mse: 1923.4982 - val_loss: 10094.8732 - val_mse: 10094.8730\n",
      "Epoch 174/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 1918.1920 - mse: 1918.1921 - val_loss: 10114.6834 - val_mse: 10114.6836\n",
      "Epoch 175/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 1918.0048 - mse: 1918.0049 - val_loss: 10007.9205 - val_mse: 10007.9209\n",
      "Epoch 176/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 1904.1254 - mse: 1904.1255 - val_loss: 10044.6815 - val_mse: 10044.6816\n",
      "Epoch 177/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 1900.2688 - mse: 1900.2688 - val_loss: 9962.8718 - val_mse: 9962.8711\n",
      "Epoch 178/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 1899.8825 - mse: 1899.8827 - val_loss: 9996.0818 - val_mse: 9996.0820\n",
      "Epoch 179/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 1897.2100 - mse: 1897.2100 - val_loss: 10047.1801 - val_mse: 10047.1797\n",
      "Epoch 180/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 1891.5395 - mse: 1891.5394 - val_loss: 10032.8603 - val_mse: 10032.8604\n",
      "Epoch 181/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 1893.4121 - mse: 1893.4120 - val_loss: 9985.5703 - val_mse: 9985.5703\n",
      "Epoch 182/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 1881.3204 - mse: 1881.3203 - val_loss: 10004.7955 - val_mse: 10004.7959\n",
      "Epoch 183/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 1882.4241 - mse: 1882.4242 - val_loss: 10075.9752 - val_mse: 10075.9756\n",
      "Epoch 184/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 1881.0539 - mse: 1881.0540 - val_loss: 10137.6245 - val_mse: 10137.6250\n",
      "Epoch 185/1000\n",
      "135/135 [==============================] - 0s 162us/sample - loss: 1885.2214 - mse: 1885.2214 - val_loss: 10042.4164 - val_mse: 10042.4160\n",
      "Epoch 186/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 1865.0278 - mse: 1865.0278 - val_loss: 9974.6926 - val_mse: 9974.6934\n",
      "Epoch 187/1000\n",
      "135/135 [==============================] - 0s 163us/sample - loss: 1867.4076 - mse: 1867.4076 - val_loss: 9931.8028 - val_mse: 9931.8037\n",
      "Epoch 188/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 1859.8214 - mse: 1859.8214 - val_loss: 9900.6356 - val_mse: 9900.6357\n",
      "Epoch 189/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 1858.3865 - mse: 1858.3864 - val_loss: 9985.1172 - val_mse: 9985.1172\n",
      "Epoch 190/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 1851.4631 - mse: 1851.4631 - val_loss: 9962.5813 - val_mse: 9962.5811\n",
      "Epoch 191/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 1855.7244 - mse: 1855.7244 - val_loss: 9971.9697 - val_mse: 9971.9697\n",
      "Epoch 192/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 1844.9615 - mse: 1844.9614 - val_loss: 9915.3539 - val_mse: 9915.3535\n",
      "Epoch 193/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 1847.2953 - mse: 1847.2952 - val_loss: 9968.0538 - val_mse: 9968.0537\n",
      "Epoch 194/1000\n",
      "135/135 [==============================] - 0s 214us/sample - loss: 1837.8854 - mse: 1837.8854 - val_loss: 10106.2583 - val_mse: 10106.2578\n",
      "Epoch 195/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 1832.3050 - mse: 1832.3049 - val_loss: 10103.9223 - val_mse: 10103.9229\n",
      "Epoch 196/1000\n",
      "135/135 [==============================] - 0s 162us/sample - loss: 1834.1014 - mse: 1834.1014 - val_loss: 10179.6512 - val_mse: 10179.6504\n",
      "Epoch 197/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 1832.6841 - mse: 1832.6841 - val_loss: 10143.9853 - val_mse: 10143.9854\n",
      "Epoch 198/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 1825.7248 - mse: 1825.7247 - val_loss: 10126.7574 - val_mse: 10126.7578\n",
      "Epoch 199/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 1826.5370 - mse: 1826.5370 - val_loss: 10085.9072 - val_mse: 10085.9072\n",
      "Epoch 200/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 1816.8521 - mse: 1816.8521 - val_loss: 9964.2505 - val_mse: 9964.2500\n",
      "Epoch 201/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 1820.0765 - mse: 1820.0767 - val_loss: 10035.9894 - val_mse: 10035.9893\n",
      "Epoch 202/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 1812.2752 - mse: 1812.2753 - val_loss: 10137.4807 - val_mse: 10137.4805\n",
      "Epoch 203/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 1807.5637 - mse: 1807.5636 - val_loss: 10204.1636 - val_mse: 10204.1641\n",
      "Epoch 204/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 1800.7296 - mse: 1800.7296 - val_loss: 10232.9421 - val_mse: 10232.9424\n",
      "Epoch 205/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 1802.0975 - mse: 1802.0974 - val_loss: 10246.4214 - val_mse: 10246.4209\n",
      "Epoch 206/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 1804.8343 - mse: 1804.8341 - val_loss: 10296.3102 - val_mse: 10296.3105\n",
      "Epoch 207/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 1797.5380 - mse: 1797.5381 - val_loss: 10296.2564 - val_mse: 10296.2568\n",
      "Epoch 208/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 1792.1699 - mse: 1792.1699 - val_loss: 10266.1843 - val_mse: 10266.1836\n",
      "Epoch 209/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 1795.5973 - mse: 1795.5972 - val_loss: 10347.4421 - val_mse: 10347.4424\n",
      "Epoch 210/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 1785.0002 - mse: 1785.0002 - val_loss: 10276.7082 - val_mse: 10276.7080\n",
      "Epoch 211/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 1777.9830 - mse: 1777.9832 - val_loss: 10240.6590 - val_mse: 10240.6592\n",
      "Epoch 212/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 1777.6100 - mse: 1777.6101 - val_loss: 10204.8300 - val_mse: 10204.8301\n",
      "Epoch 213/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 1769.9659 - mse: 1769.9659 - val_loss: 10201.0970 - val_mse: 10201.0977\n",
      "Epoch 214/1000\n",
      "135/135 [==============================] - 0s 236us/sample - loss: 1761.7114 - mse: 1761.7113 - val_loss: 10137.8401 - val_mse: 10137.8398\n",
      "Epoch 215/1000\n",
      "135/135 [==============================] - 0s 214us/sample - loss: 1764.4687 - mse: 1764.4688 - val_loss: 10166.6760 - val_mse: 10166.6768\n",
      "Epoch 216/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 1764.9097 - mse: 1764.9097 - val_loss: 10177.2137 - val_mse: 10177.2129\n",
      "Epoch 217/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 1756.5471 - mse: 1756.5471 - val_loss: 10120.4770 - val_mse: 10120.4766\n",
      "Epoch 218/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 1760.0477 - mse: 1760.0479 - val_loss: 10209.3272 - val_mse: 10209.3271\n",
      "Epoch 219/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 1748.6484 - mse: 1748.6484 - val_loss: 10226.0193 - val_mse: 10226.0195\n",
      "Epoch 220/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 1746.9414 - mse: 1746.9414 - val_loss: 10212.6461 - val_mse: 10212.6465\n",
      "Epoch 221/1000\n",
      "135/135 [==============================] - 0s 162us/sample - loss: 1740.1594 - mse: 1740.1594 - val_loss: 10174.9485 - val_mse: 10174.9482\n",
      "Epoch 222/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 1739.4592 - mse: 1739.4592 - val_loss: 10181.9596 - val_mse: 10181.9600\n",
      "Epoch 223/1000\n",
      "135/135 [==============================] - 0s 162us/sample - loss: 1739.4968 - mse: 1739.4968 - val_loss: 10199.4724 - val_mse: 10199.4727\n",
      "Epoch 224/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 1733.5137 - mse: 1733.5137 - val_loss: 10149.6443 - val_mse: 10149.6445\n",
      "Epoch 225/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 1731.7394 - mse: 1731.7395 - val_loss: 10081.7256 - val_mse: 10081.7266\n",
      "Epoch 226/1000\n",
      "135/135 [==============================] - 0s 162us/sample - loss: 1730.0999 - mse: 1730.0997 - val_loss: 10099.1751 - val_mse: 10099.1748\n",
      "Epoch 227/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 1721.5833 - mse: 1721.5834 - val_loss: 10043.2721 - val_mse: 10043.2725\n",
      "Epoch 228/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 1720.8769 - mse: 1720.8770 - val_loss: 10051.5381 - val_mse: 10051.5391\n",
      "Epoch 229/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 1719.0025 - mse: 1719.0024 - val_loss: 10122.9242 - val_mse: 10122.9248\n",
      "Epoch 230/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 1718.2499 - mse: 1718.2499 - val_loss: 10158.5216 - val_mse: 10158.5225\n",
      "Epoch 231/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 1709.1630 - mse: 1709.1630 - val_loss: 10163.5570 - val_mse: 10163.5566\n",
      "Epoch 232/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 1707.3444 - mse: 1707.3445 - val_loss: 10244.1043 - val_mse: 10244.1045\n",
      "Epoch 233/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 1701.7423 - mse: 1701.7423 - val_loss: 10295.8851 - val_mse: 10295.8848\n",
      "Epoch 234/1000\n",
      "135/135 [==============================] - 0s 214us/sample - loss: 1707.0530 - mse: 1707.0530 - val_loss: 10233.9807 - val_mse: 10233.9805\n",
      "Epoch 235/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 1704.6200 - mse: 1704.6199 - val_loss: 10263.0735 - val_mse: 10263.0732\n",
      "Epoch 236/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 1689.5098 - mse: 1689.5099 - val_loss: 10225.0184 - val_mse: 10225.0186\n",
      "Epoch 237/1000\n",
      "135/135 [==============================] - 0s 184us/sample - loss: 1695.6500 - mse: 1695.6500 - val_loss: 10116.2165 - val_mse: 10116.2168\n",
      "Epoch 238/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 1684.4569 - mse: 1684.4569 - val_loss: 10144.9995 - val_mse: 10145.0000\n",
      "Epoch 239/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 1694.5110 - mse: 1694.5109 - val_loss: 10109.8562 - val_mse: 10109.8564\n",
      "Epoch 240/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 1678.4622 - mse: 1678.4620 - val_loss: 10148.9026 - val_mse: 10148.9023\n",
      "Epoch 241/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 1673.4716 - mse: 1673.4717 - val_loss: 10167.7215 - val_mse: 10167.7217\n",
      "Epoch 242/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 1669.8933 - mse: 1669.8933 - val_loss: 10252.4416 - val_mse: 10252.4414\n",
      "Epoch 243/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 1670.2607 - mse: 1670.2606 - val_loss: 10180.1627 - val_mse: 10180.1631\n",
      "Epoch 244/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 1670.5953 - mse: 1670.5953 - val_loss: 10191.2169 - val_mse: 10191.2168\n",
      "Epoch 245/1000\n",
      "135/135 [==============================] - 0s 179us/sample - loss: 1658.2600 - mse: 1658.2600 - val_loss: 10199.6227 - val_mse: 10199.6230\n",
      "Epoch 246/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 1659.8895 - mse: 1659.8895 - val_loss: 10200.5717 - val_mse: 10200.5713\n",
      "Epoch 247/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 1659.0448 - mse: 1659.0449 - val_loss: 10236.3070 - val_mse: 10236.3066\n",
      "Epoch 248/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 1660.5824 - mse: 1660.5825 - val_loss: 10227.0561 - val_mse: 10227.0557\n",
      "Epoch 249/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 1650.3291 - mse: 1650.3291 - val_loss: 10193.8235 - val_mse: 10193.8232\n",
      "Epoch 250/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 1656.7377 - mse: 1656.7377 - val_loss: 10210.6025 - val_mse: 10210.6025\n",
      "Epoch 251/1000\n",
      "135/135 [==============================] - 0s 214us/sample - loss: 1640.3624 - mse: 1640.3627 - val_loss: 10242.5432 - val_mse: 10242.5430\n",
      "Epoch 252/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 1638.3725 - mse: 1638.3726 - val_loss: 10217.7739 - val_mse: 10217.7734\n",
      "Epoch 253/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 1642.9942 - mse: 1642.9943 - val_loss: 10210.9099 - val_mse: 10210.9102\n",
      "Epoch 254/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 1634.1052 - mse: 1634.1052 - val_loss: 10281.5542 - val_mse: 10281.5547\n",
      "Epoch 255/1000\n",
      "135/135 [==============================] - 0s 200us/sample - loss: 1637.3405 - mse: 1637.3405 - val_loss: 10177.9917 - val_mse: 10177.9922\n",
      "Epoch 256/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 1624.5711 - mse: 1624.5710 - val_loss: 10117.0193 - val_mse: 10117.0195\n",
      "Epoch 257/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 1631.8485 - mse: 1631.8485 - val_loss: 10100.0974 - val_mse: 10100.0977\n",
      "Epoch 258/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 1624.4052 - mse: 1624.4052 - val_loss: 10153.1039 - val_mse: 10153.1035\n",
      "Epoch 259/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 1619.6422 - mse: 1619.6423 - val_loss: 10153.0804 - val_mse: 10153.0811\n",
      "Epoch 260/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 1616.4939 - mse: 1616.4939 - val_loss: 10127.6884 - val_mse: 10127.6885\n",
      "Epoch 261/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 1609.8241 - mse: 1609.8242 - val_loss: 10119.6443 - val_mse: 10119.6445\n",
      "Epoch 262/1000\n",
      "135/135 [==============================] - 0s 214us/sample - loss: 1606.8036 - mse: 1606.8036 - val_loss: 10150.1645 - val_mse: 10150.1641\n",
      "Epoch 263/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 1607.3552 - mse: 1607.3553 - val_loss: 10197.0777 - val_mse: 10197.0771\n",
      "Epoch 264/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 1597.5982 - mse: 1597.5981 - val_loss: 10187.6962 - val_mse: 10187.6963\n",
      "Epoch 265/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 1598.7244 - mse: 1598.7245 - val_loss: 10345.4554 - val_mse: 10345.4561\n",
      "Epoch 266/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 1596.0293 - mse: 1596.0293 - val_loss: 10357.0744 - val_mse: 10357.0742\n",
      "Epoch 267/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 1590.7731 - mse: 1590.7731 - val_loss: 10351.4127 - val_mse: 10351.4131\n",
      "Epoch 268/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 0s 207us/sample - loss: 1587.3244 - mse: 1587.3243 - val_loss: 10316.3915 - val_mse: 10316.3916\n",
      "Epoch 269/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 1580.3965 - mse: 1580.3965 - val_loss: 10213.1494 - val_mse: 10213.1484\n",
      "Epoch 270/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 1583.9072 - mse: 1583.9072 - val_loss: 10313.6788 - val_mse: 10313.6787\n",
      "Epoch 271/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 1584.5836 - mse: 1584.5836 - val_loss: 10267.8635 - val_mse: 10267.8643\n",
      "Epoch 272/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 1572.5934 - mse: 1572.5934 - val_loss: 10290.6158 - val_mse: 10290.6162\n",
      "Epoch 273/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 1574.4075 - mse: 1574.4073 - val_loss: 10231.6659 - val_mse: 10231.6650\n",
      "Epoch 274/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 1565.2990 - mse: 1565.2991 - val_loss: 10221.9807 - val_mse: 10221.9805\n",
      "Epoch 275/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 1569.4280 - mse: 1569.4280 - val_loss: 10286.3796 - val_mse: 10286.3799\n",
      "Epoch 276/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 1557.6396 - mse: 1557.6395 - val_loss: 10288.8874 - val_mse: 10288.8877\n",
      "Epoch 277/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 1560.9117 - mse: 1560.9117 - val_loss: 10247.0524 - val_mse: 10247.0527\n",
      "Epoch 278/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 1549.4192 - mse: 1549.4192 - val_loss: 10227.1820 - val_mse: 10227.1816\n",
      "Epoch 279/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 1546.1494 - mse: 1546.1494 - val_loss: 10310.0643 - val_mse: 10310.0645\n",
      "Epoch 280/1000\n",
      "135/135 [==============================] - 0s 214us/sample - loss: 1553.9524 - mse: 1553.9524 - val_loss: 10399.7229 - val_mse: 10399.7227\n",
      "Epoch 281/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 1551.6906 - mse: 1551.6907 - val_loss: 10400.6475 - val_mse: 10400.6475\n",
      "Epoch 282/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 1542.1588 - mse: 1542.1588 - val_loss: 10397.8575 - val_mse: 10397.8574\n",
      "Epoch 283/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 1541.5912 - mse: 1541.5912 - val_loss: 10314.5662 - val_mse: 10314.5664\n",
      "Epoch 284/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 1534.6604 - mse: 1534.6604 - val_loss: 10409.3277 - val_mse: 10409.3271\n",
      "Epoch 285/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 1537.1962 - mse: 1537.1962 - val_loss: 10318.4214 - val_mse: 10318.4209\n",
      "Epoch 286/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 1529.1789 - mse: 1529.1791 - val_loss: 10306.9113 - val_mse: 10306.9121\n",
      "Epoch 287/1000\n",
      "135/135 [==============================] - 0s 200us/sample - loss: 1528.6818 - mse: 1528.6819 - val_loss: 10401.0322 - val_mse: 10401.0322\n",
      "Epoch 288/1000\n",
      "135/135 [==============================] - 0s 214us/sample - loss: 1524.9760 - mse: 1524.9761 - val_loss: 10383.2224 - val_mse: 10383.2227\n",
      "Epoch 289/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 1519.2136 - mse: 1519.2135 - val_loss: 10415.5671 - val_mse: 10415.5674\n",
      "Epoch 290/1000\n",
      "135/135 [==============================] - 0s 214us/sample - loss: 1515.9348 - mse: 1515.9347 - val_loss: 10455.5561 - val_mse: 10455.5557\n",
      "Epoch 291/1000\n",
      "135/135 [==============================] - 0s 229us/sample - loss: 1514.4852 - mse: 1514.4852 - val_loss: 10444.9720 - val_mse: 10444.9727\n",
      "Epoch 292/1000\n",
      "135/135 [==============================] - 0s 222us/sample - loss: 1514.8494 - mse: 1514.8494 - val_loss: 10456.3157 - val_mse: 10456.3164\n",
      "Epoch 293/1000\n",
      "135/135 [==============================] - 0s 236us/sample - loss: 1510.7200 - mse: 1510.7198 - val_loss: 10522.1245 - val_mse: 10522.1250\n",
      "Epoch 294/1000\n",
      "135/135 [==============================] - 0s 236us/sample - loss: 1506.4646 - mse: 1506.4646 - val_loss: 10414.7321 - val_mse: 10414.7314\n",
      "Epoch 295/1000\n",
      "135/135 [==============================] - 0s 229us/sample - loss: 1498.5784 - mse: 1498.5784 - val_loss: 10508.6034 - val_mse: 10508.6025\n",
      "Epoch 296/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 1497.2987 - mse: 1497.2987 - val_loss: 10475.5051 - val_mse: 10475.5059\n",
      "Epoch 297/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 1498.1309 - mse: 1498.1309 - val_loss: 10382.8203 - val_mse: 10382.8203\n",
      "Epoch 298/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 1495.5238 - mse: 1495.5238 - val_loss: 10367.8006 - val_mse: 10367.8008\n",
      "Epoch 299/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 1492.5925 - mse: 1492.5927 - val_loss: 10357.6158 - val_mse: 10357.6162\n",
      "Epoch 300/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 1494.9135 - mse: 1494.9136 - val_loss: 10325.9122 - val_mse: 10325.9121\n",
      "Epoch 301/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 1492.2435 - mse: 1492.2435 - val_loss: 10371.4770 - val_mse: 10371.4766\n",
      "Epoch 302/1000\n",
      "135/135 [==============================] - 0s 148us/sample - loss: 1482.6710 - mse: 1482.6710 - val_loss: 10504.5046 - val_mse: 10504.5049\n",
      "Epoch 303/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 1485.3921 - mse: 1485.3922 - val_loss: 10537.9476 - val_mse: 10537.9473\n",
      "Epoch 304/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 1483.4055 - mse: 1483.4054 - val_loss: 10494.3851 - val_mse: 10494.3848\n",
      "Epoch 305/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 1474.0475 - mse: 1474.0475 - val_loss: 10498.3511 - val_mse: 10498.3516\n",
      "Epoch 306/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 1471.3371 - mse: 1471.3372 - val_loss: 10379.1199 - val_mse: 10379.1191\n",
      "Epoch 307/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 1463.6747 - mse: 1463.6747 - val_loss: 10424.3998 - val_mse: 10424.3994\n",
      "Epoch 308/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 1467.4964 - mse: 1467.4963 - val_loss: 10499.1268 - val_mse: 10499.1270\n",
      "Epoch 309/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 1460.0199 - mse: 1460.0200 - val_loss: 10494.0565 - val_mse: 10494.0566\n",
      "Epoch 310/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 1460.9836 - mse: 1460.9835 - val_loss: 10376.5106 - val_mse: 10376.5107\n",
      "Epoch 311/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 1451.9602 - mse: 1451.9602 - val_loss: 10404.6668 - val_mse: 10404.6670\n",
      "Epoch 312/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 1456.9186 - mse: 1456.9186 - val_loss: 10494.4665 - val_mse: 10494.4668\n",
      "Epoch 313/1000\n",
      "135/135 [==============================] - 0s 163us/sample - loss: 1456.1863 - mse: 1456.1864 - val_loss: 10502.6278 - val_mse: 10502.6279\n",
      "Epoch 314/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 1449.5312 - mse: 1449.5311 - val_loss: 10442.6627 - val_mse: 10442.6631\n",
      "Epoch 315/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 1445.5321 - mse: 1445.5321 - val_loss: 10448.5432 - val_mse: 10448.5430\n",
      "Epoch 316/1000\n",
      "135/135 [==============================] - 0s 163us/sample - loss: 1439.8947 - mse: 1439.8947 - val_loss: 10463.6287 - val_mse: 10463.6289\n",
      "Epoch 317/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 1432.7828 - mse: 1432.7827 - val_loss: 10480.0179 - val_mse: 10480.0186\n",
      "Epoch 318/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 1442.5128 - mse: 1442.5127 - val_loss: 10514.5662 - val_mse: 10514.5664\n",
      "Epoch 319/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 1433.7801 - mse: 1433.7802 - val_loss: 10400.0257 - val_mse: 10400.0254\n",
      "Epoch 320/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 1431.8331 - mse: 1431.8331 - val_loss: 10453.3267 - val_mse: 10453.3271\n",
      "Epoch 321/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 1425.2645 - mse: 1425.2645 - val_loss: 10461.7100 - val_mse: 10461.7100\n",
      "Epoch 322/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 1432.7407 - mse: 1432.7407 - val_loss: 10462.5404 - val_mse: 10462.5400\n",
      "Epoch 323/1000\n",
      "135/135 [==============================] - 0s 155us/sample - loss: 1421.0843 - mse: 1421.0844 - val_loss: 10474.2119 - val_mse: 10474.2109\n",
      "Epoch 324/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 1418.4555 - mse: 1418.4556 - val_loss: 10476.3295 - val_mse: 10476.3291\n",
      "Epoch 325/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 1424.6338 - mse: 1424.6338 - val_loss: 10450.1264 - val_mse: 10450.1270\n",
      "Epoch 326/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 1408.8490 - mse: 1408.8489 - val_loss: 10451.1029 - val_mse: 10451.1025\n",
      "Epoch 327/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 1411.2198 - mse: 1411.2198 - val_loss: 10462.4044 - val_mse: 10462.4043\n",
      "Epoch 328/1000\n",
      "135/135 [==============================] - 0s 155us/sample - loss: 1407.5337 - mse: 1407.5336 - val_loss: 10463.5910 - val_mse: 10463.5908\n",
      "Epoch 329/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 1404.7664 - mse: 1404.7664 - val_loss: 10480.1131 - val_mse: 10480.1133\n",
      "Epoch 330/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 1406.2816 - mse: 1406.2816 - val_loss: 10442.6792 - val_mse: 10442.6797\n",
      "Epoch 331/1000\n",
      "135/135 [==============================] - 0s 163us/sample - loss: 1399.5603 - mse: 1399.5603 - val_loss: 10480.2702 - val_mse: 10480.2705\n",
      "Epoch 332/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 1394.3714 - mse: 1394.3715 - val_loss: 10458.6020 - val_mse: 10458.6016\n",
      "Epoch 333/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 1395.3045 - mse: 1395.3044 - val_loss: 10515.7698 - val_mse: 10515.7705\n",
      "Epoch 334/1000\n",
      "135/135 [==============================] - 0s 184us/sample - loss: 1387.8370 - mse: 1387.8370 - val_loss: 10487.7840 - val_mse: 10487.7842\n",
      "Epoch 335/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 1395.6166 - mse: 1395.6166 - val_loss: 10505.1994 - val_mse: 10505.1992\n",
      "Epoch 336/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 1383.2346 - mse: 1383.2346 - val_loss: 10544.6025 - val_mse: 10544.6025\n",
      "Epoch 337/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 1388.0388 - mse: 1388.0389 - val_loss: 10561.3111 - val_mse: 10561.3105\n",
      "Epoch 338/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 1383.2789 - mse: 1383.2788 - val_loss: 10577.4154 - val_mse: 10577.4150\n",
      "Epoch 339/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 1382.1486 - mse: 1382.1486 - val_loss: 10593.2054 - val_mse: 10593.2061\n",
      "Epoch 340/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 1374.4823 - mse: 1374.4822 - val_loss: 10603.1939 - val_mse: 10603.1943\n",
      "Epoch 341/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 1364.5928 - mse: 1364.5928 - val_loss: 10645.7730 - val_mse: 10645.7734\n",
      "Epoch 342/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 1372.6020 - mse: 1372.6019 - val_loss: 10684.1213 - val_mse: 10684.1211\n",
      "Epoch 343/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 1367.2784 - mse: 1367.2784 - val_loss: 10566.8493 - val_mse: 10566.8496\n",
      "Epoch 344/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 1362.3354 - mse: 1362.3354 - val_loss: 10650.6383 - val_mse: 10650.6377\n",
      "Epoch 345/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 1357.7732 - mse: 1357.7733 - val_loss: 10633.0202 - val_mse: 10633.0205\n",
      "Epoch 346/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 1364.2530 - mse: 1364.2531 - val_loss: 10642.7606 - val_mse: 10642.7607\n",
      "Epoch 347/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 1357.4051 - mse: 1357.4052 - val_loss: 10550.3768 - val_mse: 10550.3770\n",
      "Epoch 348/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 1349.6704 - mse: 1349.6705 - val_loss: 10545.1374 - val_mse: 10545.1377\n",
      "Epoch 349/1000\n",
      "135/135 [==============================] - 0s 184us/sample - loss: 1348.3114 - mse: 1348.3114 - val_loss: 10606.7362 - val_mse: 10606.7363\n",
      "Epoch 350/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 1345.2882 - mse: 1345.2883 - val_loss: 10605.4706 - val_mse: 10605.4707\n",
      "Epoch 351/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 1341.7501 - mse: 1341.7500 - val_loss: 10711.5202 - val_mse: 10711.5205\n",
      "Epoch 352/1000\n",
      "135/135 [==============================] - 0s 184us/sample - loss: 1337.9531 - mse: 1337.9531 - val_loss: 10689.8952 - val_mse: 10689.8955\n",
      "Epoch 353/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 1343.4814 - mse: 1343.4813 - val_loss: 10742.5561 - val_mse: 10742.5557\n",
      "Epoch 354/1000\n",
      "135/135 [==============================] - 0s 214us/sample - loss: 1334.2193 - mse: 1334.2194 - val_loss: 10725.5519 - val_mse: 10725.5518\n",
      "Epoch 355/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 1336.5852 - mse: 1336.5853 - val_loss: 10697.5404 - val_mse: 10697.5400\n",
      "Epoch 356/1000\n",
      "135/135 [==============================] - 0s 174us/sample - loss: 1337.2715 - mse: 1337.2714 - val_loss: 10722.2578 - val_mse: 10722.2578\n",
      "Epoch 357/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 1334.6619 - mse: 1334.6619 - val_loss: 10763.8102 - val_mse: 10763.8105\n",
      "Epoch 358/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 1333.9225 - mse: 1333.9226 - val_loss: 10776.3451 - val_mse: 10776.3457\n",
      "Epoch 359/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 1324.5674 - mse: 1324.5674 - val_loss: 10819.3755 - val_mse: 10819.3750\n",
      "Epoch 360/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 1320.7180 - mse: 1320.7179 - val_loss: 10777.3300 - val_mse: 10777.3301\n",
      "Epoch 361/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 1324.0048 - mse: 1324.0048 - val_loss: 10765.3621 - val_mse: 10765.3623\n",
      "Epoch 362/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 1311.8867 - mse: 1311.8866 - val_loss: 10834.6824 - val_mse: 10834.6816\n",
      "Epoch 363/1000\n",
      "135/135 [==============================] - 0s 163us/sample - loss: 1313.0504 - mse: 1313.0503 - val_loss: 10833.3084 - val_mse: 10833.3086\n",
      "Epoch 364/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 1313.7681 - mse: 1313.7681 - val_loss: 10723.9283 - val_mse: 10723.9287\n",
      "Epoch 365/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 1319.8909 - mse: 1319.8909 - val_loss: 10683.0584 - val_mse: 10683.0586\n",
      "Epoch 366/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 1306.7757 - mse: 1306.7756 - val_loss: 10696.3580 - val_mse: 10696.3584\n",
      "Epoch 367/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 1304.2513 - mse: 1304.2512 - val_loss: 10723.5460 - val_mse: 10723.5459\n",
      "Epoch 368/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 1298.7136 - mse: 1298.7136 - val_loss: 10729.5234 - val_mse: 10729.5234\n",
      "Epoch 369/1000\n",
      "135/135 [==============================] - 0s 178us/sample - loss: 1293.9565 - mse: 1293.9564 - val_loss: 10774.9136 - val_mse: 10774.9141\n",
      "Epoch 370/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 1293.2759 - mse: 1293.2759 - val_loss: 10886.7509 - val_mse: 10886.7510\n",
      "Epoch 371/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 1297.5679 - mse: 1297.5680 - val_loss: 10860.1420 - val_mse: 10860.1416\n",
      "Epoch 372/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 1292.0725 - mse: 1292.0725 - val_loss: 10845.4490 - val_mse: 10845.4482\n",
      "Epoch 373/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 1291.4244 - mse: 1291.4244 - val_loss: 10816.9012 - val_mse: 10816.9004\n",
      "Epoch 374/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 0s 199us/sample - loss: 1280.6863 - mse: 1280.6864 - val_loss: 10807.7068 - val_mse: 10807.7070\n",
      "Epoch 375/1000\n",
      "135/135 [==============================] - 0s 222us/sample - loss: 1278.6480 - mse: 1278.6482 - val_loss: 10829.6080 - val_mse: 10829.6084\n",
      "Epoch 376/1000\n",
      "135/135 [==============================] - 0s 251us/sample - loss: 1276.0869 - mse: 1276.0869 - val_loss: 10753.2188 - val_mse: 10753.2188\n",
      "Epoch 377/1000\n",
      "135/135 [==============================] - 0s 222us/sample - loss: 1268.8417 - mse: 1268.8418 - val_loss: 10785.5386 - val_mse: 10785.5391\n",
      "Epoch 378/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 1278.4965 - mse: 1278.4966 - val_loss: 10809.5754 - val_mse: 10809.5752\n",
      "Epoch 379/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 1265.1771 - mse: 1265.1771 - val_loss: 10810.6121 - val_mse: 10810.6123\n",
      "Epoch 380/1000\n",
      "135/135 [==============================] - 0s 184us/sample - loss: 1270.0326 - mse: 1270.0326 - val_loss: 10833.1328 - val_mse: 10833.1328\n",
      "Epoch 381/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 1260.4443 - mse: 1260.4442 - val_loss: 10883.3768 - val_mse: 10883.3770\n",
      "Epoch 382/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 1266.1224 - mse: 1266.1223 - val_loss: 10837.6098 - val_mse: 10837.6104\n",
      "Epoch 383/1000\n",
      "135/135 [==============================] - 0s 155us/sample - loss: 1260.9218 - mse: 1260.9218 - val_loss: 10863.6305 - val_mse: 10863.6309\n",
      "Epoch 384/1000\n",
      "135/135 [==============================] - 0s 162us/sample - loss: 1261.7574 - mse: 1261.7574 - val_loss: 10885.3286 - val_mse: 10885.3291\n",
      "Epoch 385/1000\n",
      "135/135 [==============================] - 0s 163us/sample - loss: 1255.3139 - mse: 1255.3140 - val_loss: 10901.7114 - val_mse: 10901.7109\n",
      "Epoch 386/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 1268.5902 - mse: 1268.5903 - val_loss: 10915.9012 - val_mse: 10915.9004\n",
      "Epoch 387/1000\n",
      "135/135 [==============================] - 0s 162us/sample - loss: 1249.3867 - mse: 1249.3867 - val_loss: 10884.7895 - val_mse: 10884.7891\n",
      "Epoch 388/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 1244.6029 - mse: 1244.6029 - val_loss: 10984.0685 - val_mse: 10984.0684\n",
      "Epoch 389/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 1246.5249 - mse: 1246.5250 - val_loss: 10977.3984 - val_mse: 10977.3984\n",
      "Epoch 390/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 1245.4480 - mse: 1245.4480 - val_loss: 10999.3676 - val_mse: 10999.3672\n",
      "Epoch 391/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 1243.3209 - mse: 1243.3209 - val_loss: 10957.9674 - val_mse: 10957.9668\n",
      "Epoch 392/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 1241.6705 - mse: 1241.6707 - val_loss: 10957.5469 - val_mse: 10957.5469\n",
      "Epoch 393/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 1233.5402 - mse: 1233.5402 - val_loss: 10851.3534 - val_mse: 10851.3525\n",
      "Epoch 394/1000\n",
      "135/135 [==============================] - 0s 229us/sample - loss: 1236.3005 - mse: 1236.3004 - val_loss: 10794.7780 - val_mse: 10794.7773\n",
      "Epoch 395/1000\n",
      "135/135 [==============================] - 0s 214us/sample - loss: 1229.4154 - mse: 1229.4154 - val_loss: 10821.0988 - val_mse: 10821.0996\n",
      "Epoch 396/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 1229.3013 - mse: 1229.3013 - val_loss: 10849.2082 - val_mse: 10849.2080\n",
      "Epoch 397/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 1223.5107 - mse: 1223.5107 - val_loss: 10914.2748 - val_mse: 10914.2744\n",
      "Epoch 398/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 1224.2535 - mse: 1224.2534 - val_loss: 10932.6544 - val_mse: 10932.6543\n",
      "Epoch 399/1000\n",
      "135/135 [==============================] - 0s 155us/sample - loss: 1224.1774 - mse: 1224.1775 - val_loss: 10880.4830 - val_mse: 10880.4834\n",
      "Epoch 400/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 1214.7628 - mse: 1214.7627 - val_loss: 10819.5312 - val_mse: 10819.5312\n",
      "Epoch 401/1000\n",
      "135/135 [==============================] - 0s 163us/sample - loss: 1222.2735 - mse: 1222.2734 - val_loss: 10761.7578 - val_mse: 10761.7578\n",
      "Epoch 402/1000\n",
      "135/135 [==============================] - 0s 163us/sample - loss: 1212.6644 - mse: 1212.6643 - val_loss: 10740.6020 - val_mse: 10740.6016\n",
      "Epoch 403/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 1214.6409 - mse: 1214.6409 - val_loss: 10704.1057 - val_mse: 10704.1055\n",
      "Epoch 404/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 1216.0525 - mse: 1216.0525 - val_loss: 10757.9697 - val_mse: 10757.9697\n",
      "Epoch 405/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 1211.2197 - mse: 1211.2198 - val_loss: 10823.2082 - val_mse: 10823.2080\n",
      "Epoch 406/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 1201.2857 - mse: 1201.2858 - val_loss: 10780.7868 - val_mse: 10780.7871\n",
      "Epoch 407/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 1205.5102 - mse: 1205.5101 - val_loss: 10816.7790 - val_mse: 10816.7793\n",
      "Epoch 408/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 1199.5918 - mse: 1199.5919 - val_loss: 10784.4159 - val_mse: 10784.4150\n",
      "Epoch 409/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 1203.1943 - mse: 1203.1942 - val_loss: 10926.0303 - val_mse: 10926.0303\n",
      "Epoch 410/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 1198.4883 - mse: 1198.4884 - val_loss: 10871.9260 - val_mse: 10871.9268\n",
      "Epoch 411/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 1188.7659 - mse: 1188.7659 - val_loss: 10942.8851 - val_mse: 10942.8848\n",
      "Epoch 412/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 1198.9318 - mse: 1198.9318 - val_loss: 10960.6195 - val_mse: 10960.6191\n",
      "Epoch 413/1000\n",
      "135/135 [==============================] - 0s 222us/sample - loss: 1190.4691 - mse: 1190.4691 - val_loss: 11087.3506 - val_mse: 11087.3516\n",
      "Epoch 414/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 1184.4257 - mse: 1184.4257 - val_loss: 11155.3033 - val_mse: 11155.3037\n",
      "Epoch 415/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 1183.4234 - mse: 1183.4233 - val_loss: 11082.5322 - val_mse: 11082.5322\n",
      "Epoch 416/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 1183.9743 - mse: 1183.9744 - val_loss: 10913.4619 - val_mse: 10913.4609\n",
      "Epoch 417/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 1174.5061 - mse: 1174.5061 - val_loss: 10930.1507 - val_mse: 10930.1504\n",
      "Epoch 418/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 1170.2527 - mse: 1170.2527 - val_loss: 10865.1806 - val_mse: 10865.1797\n",
      "Epoch 419/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 1177.3032 - mse: 1177.3032 - val_loss: 10891.1167 - val_mse: 10891.1172\n",
      "Epoch 420/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 1177.2531 - mse: 1177.2531 - val_loss: 10911.7606 - val_mse: 10911.7607\n",
      "Epoch 421/1000\n",
      "135/135 [==============================] - 0s 214us/sample - loss: 1164.3553 - mse: 1164.3553 - val_loss: 10963.8180 - val_mse: 10963.8184\n",
      "Epoch 422/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 1168.7811 - mse: 1168.7811 - val_loss: 10902.5519 - val_mse: 10902.5518\n",
      "Epoch 423/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 1163.8009 - mse: 1163.8009 - val_loss: 10971.3961 - val_mse: 10971.3965\n",
      "Epoch 424/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 1161.7673 - mse: 1161.7672 - val_loss: 10930.7119 - val_mse: 10930.7109\n",
      "Epoch 425/1000\n",
      "135/135 [==============================] - 0s 214us/sample - loss: 1160.3684 - mse: 1160.3684 - val_loss: 10984.8539 - val_mse: 10984.8535\n",
      "Epoch 426/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 1157.4722 - mse: 1157.4722 - val_loss: 11068.1089 - val_mse: 11068.1084\n",
      "Epoch 427/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 1159.7537 - mse: 1159.7535 - val_loss: 11173.0138 - val_mse: 11173.0137\n",
      "Epoch 428/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 1159.0815 - mse: 1159.0815 - val_loss: 11150.0271 - val_mse: 11150.0273\n",
      "Epoch 429/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 1151.3406 - mse: 1151.3406 - val_loss: 11254.3474 - val_mse: 11254.3477\n",
      "Epoch 430/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 1152.9084 - mse: 1152.9084 - val_loss: 11284.2960 - val_mse: 11284.2959\n",
      "Epoch 431/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 1140.9155 - mse: 1140.9155 - val_loss: 11282.8768 - val_mse: 11282.8770\n",
      "Epoch 432/1000\n",
      "135/135 [==============================] - 0s 155us/sample - loss: 1142.9119 - mse: 1142.9119 - val_loss: 11074.4903 - val_mse: 11074.4912\n",
      "Epoch 433/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 1141.4057 - mse: 1141.4055 - val_loss: 11065.9444 - val_mse: 11065.9453\n",
      "Epoch 434/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 1135.7915 - mse: 1135.7915 - val_loss: 11137.3787 - val_mse: 11137.3789\n",
      "Epoch 435/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 1144.7522 - mse: 1144.7522 - val_loss: 11162.9876 - val_mse: 11162.9873\n",
      "Epoch 436/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 1138.8171 - mse: 1138.8171 - val_loss: 11148.9366 - val_mse: 11148.9365\n",
      "Epoch 437/1000\n",
      "135/135 [==============================] - 0s 244us/sample - loss: 1128.0277 - mse: 1128.0276 - val_loss: 11254.8134 - val_mse: 11254.8135\n",
      "Epoch 438/1000\n",
      "135/135 [==============================] - 0s 214us/sample - loss: 1129.3717 - mse: 1129.3717 - val_loss: 11191.2642 - val_mse: 11191.2646\n",
      "Epoch 439/1000\n",
      "135/135 [==============================] - 0s 251us/sample - loss: 1126.4647 - mse: 1126.4647 - val_loss: 11115.9380 - val_mse: 11115.9375\n",
      "Epoch 440/1000\n",
      "135/135 [==============================] - 0s 229us/sample - loss: 1127.9385 - mse: 1127.9385 - val_loss: 11118.2362 - val_mse: 11118.2363\n",
      "Epoch 441/1000\n",
      "135/135 [==============================] - 0s 244us/sample - loss: 1130.0677 - mse: 1130.0677 - val_loss: 11098.0483 - val_mse: 11098.0479\n",
      "Epoch 442/1000\n",
      "135/135 [==============================] - 0s 214us/sample - loss: 1126.4586 - mse: 1126.4587 - val_loss: 10964.4182 - val_mse: 10964.4180\n",
      "Epoch 443/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 1118.8871 - mse: 1118.8872 - val_loss: 11025.0823 - val_mse: 11025.0830\n",
      "Epoch 444/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 1118.6906 - mse: 1118.6908 - val_loss: 11008.6507 - val_mse: 11008.6504\n",
      "Epoch 445/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 1107.2627 - mse: 1107.2627 - val_loss: 11164.0409 - val_mse: 11164.0400\n",
      "Epoch 446/1000\n",
      "135/135 [==============================] - 0s 163us/sample - loss: 1115.0232 - mse: 1115.0232 - val_loss: 11118.6347 - val_mse: 11118.6338\n",
      "Epoch 447/1000\n",
      "135/135 [==============================] - 0s 155us/sample - loss: 1110.3084 - mse: 1110.3083 - val_loss: 11098.7629 - val_mse: 11098.7627\n",
      "Epoch 448/1000\n",
      "135/135 [==============================] - 0s 155us/sample - loss: 1108.5243 - mse: 1108.5243 - val_loss: 11196.7574 - val_mse: 11196.7578\n",
      "Epoch 449/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 1103.5830 - mse: 1103.5829 - val_loss: 11248.3658 - val_mse: 11248.3662\n",
      "Epoch 450/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 1108.3792 - mse: 1108.3793 - val_loss: 11156.5064 - val_mse: 11156.5068\n",
      "Epoch 451/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 1097.6936 - mse: 1097.6935 - val_loss: 11115.0579 - val_mse: 11115.0576\n",
      "Epoch 452/1000\n",
      "135/135 [==============================] - 0s 163us/sample - loss: 1098.8678 - mse: 1098.8678 - val_loss: 11149.9825 - val_mse: 11149.9824\n",
      "Epoch 453/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 1093.4665 - mse: 1093.4664 - val_loss: 11054.2247 - val_mse: 11054.2246\n",
      "Epoch 454/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 1091.0392 - mse: 1091.0392 - val_loss: 11241.3240 - val_mse: 11241.3232\n",
      "Epoch 455/1000\n",
      "135/135 [==============================] - 0s 163us/sample - loss: 1092.4988 - mse: 1092.4989 - val_loss: 11232.0951 - val_mse: 11232.0957\n",
      "Epoch 456/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 1085.0995 - mse: 1085.0995 - val_loss: 11256.0308 - val_mse: 11256.0312\n",
      "Epoch 457/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 1089.0003 - mse: 1089.0002 - val_loss: 11190.2675 - val_mse: 11190.2676\n",
      "Epoch 458/1000\n",
      "135/135 [==============================] - 0s 214us/sample - loss: 1087.0864 - mse: 1087.0863 - val_loss: 11197.2693 - val_mse: 11197.2695\n",
      "Epoch 459/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 1081.3937 - mse: 1081.3937 - val_loss: 11291.9793 - val_mse: 11291.9795\n",
      "Epoch 460/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 1081.1742 - mse: 1081.1742 - val_loss: 11158.4426 - val_mse: 11158.4434\n",
      "Epoch 461/1000\n",
      "135/135 [==============================] - 0s 214us/sample - loss: 1080.0136 - mse: 1080.0137 - val_loss: 11134.2633 - val_mse: 11134.2627\n",
      "Epoch 462/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 1076.3787 - mse: 1076.3787 - val_loss: 11211.1365 - val_mse: 11211.1357\n",
      "Epoch 463/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 1089.4951 - mse: 1089.4950 - val_loss: 11243.5859 - val_mse: 11243.5859\n",
      "Epoch 464/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 1074.6614 - mse: 1074.6614 - val_loss: 11285.0326 - val_mse: 11285.0332\n",
      "Epoch 465/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 1078.5976 - mse: 1078.5977 - val_loss: 11235.6953 - val_mse: 11235.6953\n",
      "Epoch 466/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 1068.6972 - mse: 1068.6973 - val_loss: 11204.4311 - val_mse: 11204.4307\n",
      "Epoch 467/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 1067.7071 - mse: 1067.7070 - val_loss: 11192.9462 - val_mse: 11192.9463\n",
      "Epoch 468/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 1069.3905 - mse: 1069.3905 - val_loss: 11241.2881 - val_mse: 11241.2891\n",
      "Epoch 469/1000\n",
      "135/135 [==============================] - 0s 163us/sample - loss: 1059.5166 - mse: 1059.5166 - val_loss: 11371.0763 - val_mse: 11371.0762\n",
      "Epoch 470/1000\n",
      "135/135 [==============================] - 0s 155us/sample - loss: 1063.9395 - mse: 1063.9395 - val_loss: 11181.7693 - val_mse: 11181.7695\n",
      "Epoch 471/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 1056.0216 - mse: 1056.0217 - val_loss: 11301.7105 - val_mse: 11301.7109\n",
      "Epoch 472/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 1055.1517 - mse: 1055.1516 - val_loss: 11382.3203 - val_mse: 11382.3203\n",
      "Epoch 473/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 1060.0188 - mse: 1060.0189 - val_loss: 11433.3010 - val_mse: 11433.3018\n",
      "Epoch 474/1000\n",
      "135/135 [==============================] - 0s 183us/sample - loss: 1058.8547 - mse: 1058.8547 - val_loss: 11408.0267 - val_mse: 11408.0264\n",
      "Epoch 475/1000\n",
      "135/135 [==============================] - 0s 163us/sample - loss: 1056.0185 - mse: 1056.0186 - val_loss: 11527.7114 - val_mse: 11527.7109\n",
      "Epoch 476/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 1052.4291 - mse: 1052.4291 - val_loss: 11489.5501 - val_mse: 11489.5498\n",
      "Epoch 477/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 1047.9947 - mse: 1047.9946 - val_loss: 11523.2541 - val_mse: 11523.2539\n",
      "Epoch 478/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 1048.4343 - mse: 1048.4342 - val_loss: 11337.3975 - val_mse: 11337.3975\n",
      "Epoch 479/1000\n",
      "135/135 [==============================] - 0s 163us/sample - loss: 1049.3543 - mse: 1049.3542 - val_loss: 11324.2440 - val_mse: 11324.2441\n",
      "Epoch 480/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 0s 177us/sample - loss: 1040.9205 - mse: 1040.9205 - val_loss: 11247.8594 - val_mse: 11247.8594\n",
      "Epoch 481/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 1037.2457 - mse: 1037.2457 - val_loss: 11291.8653 - val_mse: 11291.8662\n",
      "Epoch 482/1000\n",
      "135/135 [==============================] - 0s 163us/sample - loss: 1036.3040 - mse: 1036.3041 - val_loss: 11238.5244 - val_mse: 11238.5234\n",
      "Epoch 483/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 1036.1092 - mse: 1036.1091 - val_loss: 11156.0735 - val_mse: 11156.0732\n",
      "Epoch 484/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 1036.2645 - mse: 1036.2645 - val_loss: 11309.3506 - val_mse: 11309.3516\n",
      "Epoch 485/1000\n",
      "135/135 [==============================] - 0s 163us/sample - loss: 1035.5838 - mse: 1035.5837 - val_loss: 11328.5308 - val_mse: 11328.5312\n",
      "Epoch 486/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 1032.3997 - mse: 1032.3998 - val_loss: 11332.5345 - val_mse: 11332.5352\n",
      "Epoch 487/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 1040.3928 - mse: 1040.3927 - val_loss: 11210.0014 - val_mse: 11210.0020\n",
      "Epoch 488/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 1030.5414 - mse: 1030.5414 - val_loss: 11262.4881 - val_mse: 11262.4883\n",
      "Epoch 489/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 1038.8380 - mse: 1038.8381 - val_loss: 11358.9292 - val_mse: 11358.9297\n",
      "Epoch 490/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 1016.6436 - mse: 1016.6436 - val_loss: 11383.0997 - val_mse: 11383.0996\n",
      "Epoch 491/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 1016.2983 - mse: 1016.2983 - val_loss: 11325.3493 - val_mse: 11325.3496\n",
      "Epoch 492/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 1023.2541 - mse: 1023.2540 - val_loss: 11349.9766 - val_mse: 11349.9766\n",
      "Epoch 493/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 1019.7825 - mse: 1019.7825 - val_loss: 11340.6824 - val_mse: 11340.6816\n",
      "Epoch 494/1000\n",
      "135/135 [==============================] - 0s 163us/sample - loss: 1010.1882 - mse: 1010.1882 - val_loss: 11523.3093 - val_mse: 11523.3086\n",
      "Epoch 495/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 1014.4153 - mse: 1014.4153 - val_loss: 11610.5101 - val_mse: 11610.5098\n",
      "Epoch 496/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 1012.1891 - mse: 1012.1890 - val_loss: 11532.9747 - val_mse: 11532.9746\n",
      "Epoch 497/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 1007.1772 - mse: 1007.1772 - val_loss: 11459.0267 - val_mse: 11459.0264\n",
      "Epoch 498/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 1005.6762 - mse: 1005.6761 - val_loss: 11449.1411 - val_mse: 11449.1416\n",
      "Epoch 499/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 1005.1037 - mse: 1005.1037 - val_loss: 11408.8497 - val_mse: 11408.8496\n",
      "Epoch 500/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 1000.8114 - mse: 1000.8113 - val_loss: 11451.8534 - val_mse: 11451.8525\n",
      "Epoch 501/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 1001.7766 - mse: 1001.7765 - val_loss: 11452.0938 - val_mse: 11452.0938\n",
      "Epoch 502/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 999.6130 - mse: 999.6130 - val_loss: 11518.5597 - val_mse: 11518.5596\n",
      "Epoch 503/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 997.7946 - mse: 997.7946 - val_loss: 11524.0882 - val_mse: 11524.0879\n",
      "Epoch 504/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 994.5756 - mse: 994.5757 - val_loss: 11435.9196 - val_mse: 11435.9189\n",
      "Epoch 505/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 994.0885 - mse: 994.0886 - val_loss: 11501.3359 - val_mse: 11501.3359\n",
      "Epoch 506/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 990.3795 - mse: 990.3795 - val_loss: 11616.8773 - val_mse: 11616.8770\n",
      "Epoch 507/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 991.5624 - mse: 991.5625 - val_loss: 11623.3033 - val_mse: 11623.3037\n",
      "Epoch 508/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 982.3079 - mse: 982.3079 - val_loss: 11649.1677 - val_mse: 11649.1670\n",
      "Epoch 509/1000\n",
      "135/135 [==============================] - 0s 211us/sample - loss: 988.9448 - mse: 988.9448 - val_loss: 11677.5404 - val_mse: 11677.5400\n",
      "Epoch 510/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 985.5405 - mse: 985.5405 - val_loss: 11562.7725 - val_mse: 11562.7725\n",
      "Epoch 511/1000\n",
      "135/135 [==============================] - 0s 222us/sample - loss: 985.8292 - mse: 985.8293 - val_loss: 11694.2381 - val_mse: 11694.2383\n",
      "Epoch 512/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 979.0425 - mse: 979.0426 - val_loss: 11706.0492 - val_mse: 11706.0498\n",
      "Epoch 513/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 975.6115 - mse: 975.6116 - val_loss: 11680.6342 - val_mse: 11680.6338\n",
      "Epoch 514/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 979.8906 - mse: 979.8906 - val_loss: 11767.0207 - val_mse: 11767.0205\n",
      "Epoch 515/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 972.4104 - mse: 972.4104 - val_loss: 11751.8709 - val_mse: 11751.8711\n",
      "Epoch 516/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 976.0329 - mse: 976.0329 - val_loss: 11555.3736 - val_mse: 11555.3730\n",
      "Epoch 517/1000\n",
      "135/135 [==============================] - 0s 194us/sample - loss: 969.1823 - mse: 969.1823 - val_loss: 11576.3290 - val_mse: 11576.3291\n",
      "Epoch 518/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 974.4622 - mse: 974.4623 - val_loss: 11554.1962 - val_mse: 11554.1963\n",
      "Epoch 519/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 965.9351 - mse: 965.9351 - val_loss: 11481.7192 - val_mse: 11481.7188\n",
      "Epoch 520/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 975.6479 - mse: 975.6479 - val_loss: 11482.4329 - val_mse: 11482.4326\n",
      "Epoch 521/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 967.3061 - mse: 967.3061 - val_loss: 11607.9462 - val_mse: 11607.9463\n",
      "Epoch 522/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 954.5673 - mse: 954.5673 - val_loss: 11663.3879 - val_mse: 11663.3877\n",
      "Epoch 523/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 952.9478 - mse: 952.9479 - val_loss: 11716.1847 - val_mse: 11716.1846\n",
      "Epoch 524/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 953.8441 - mse: 953.8442 - val_loss: 11612.5836 - val_mse: 11612.5840\n",
      "Epoch 525/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 955.3752 - mse: 955.3752 - val_loss: 11493.7978 - val_mse: 11493.7979\n",
      "Epoch 526/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 959.3192 - mse: 959.3192 - val_loss: 11592.0308 - val_mse: 11592.0312\n",
      "Epoch 527/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 950.6704 - mse: 950.6703 - val_loss: 11696.8483 - val_mse: 11696.8486\n",
      "Epoch 528/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 947.6766 - mse: 947.6766 - val_loss: 11676.6369 - val_mse: 11676.6367\n",
      "Epoch 529/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 956.8465 - mse: 956.8466 - val_loss: 11659.9522 - val_mse: 11659.9521\n",
      "Epoch 530/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 952.0241 - mse: 952.0241 - val_loss: 11662.6369 - val_mse: 11662.6367\n",
      "Epoch 531/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 947.2544 - mse: 947.2545 - val_loss: 11489.4582 - val_mse: 11489.4580\n",
      "Epoch 532/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 943.6608 - mse: 943.6609 - val_loss: 11636.4366 - val_mse: 11636.4365\n",
      "Epoch 533/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 935.2906 - mse: 935.2906 - val_loss: 11772.2858 - val_mse: 11772.2861\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 534/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 941.2984 - mse: 941.2983 - val_loss: 11618.3920 - val_mse: 11618.3916\n",
      "Epoch 535/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 949.0338 - mse: 949.0338 - val_loss: 11633.0547 - val_mse: 11633.0547\n",
      "Epoch 536/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 933.8049 - mse: 933.8050 - val_loss: 11581.2895 - val_mse: 11581.2891\n",
      "Epoch 537/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 930.6193 - mse: 930.6193 - val_loss: 11661.7206 - val_mse: 11661.7207\n",
      "Epoch 538/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 940.2310 - mse: 940.2310 - val_loss: 11648.6852 - val_mse: 11648.6855\n",
      "Epoch 539/1000\n",
      "135/135 [==============================] - 0s 184us/sample - loss: 926.9178 - mse: 926.9177 - val_loss: 11500.9848 - val_mse: 11500.9854\n",
      "Epoch 540/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 925.5025 - mse: 925.5025 - val_loss: 11440.5115 - val_mse: 11440.5107\n",
      "Epoch 541/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 927.8426 - mse: 927.8426 - val_loss: 11604.8290 - val_mse: 11604.8291\n",
      "Epoch 542/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 921.3030 - mse: 921.3030 - val_loss: 11689.0216 - val_mse: 11689.0225\n",
      "Epoch 543/1000\n",
      "135/135 [==============================] - 0s 214us/sample - loss: 925.2261 - mse: 925.2261 - val_loss: 11858.4724 - val_mse: 11858.4727\n",
      "Epoch 544/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 924.5245 - mse: 924.5245 - val_loss: 11837.1866 - val_mse: 11837.1865\n",
      "Epoch 545/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 918.9079 - mse: 918.9078 - val_loss: 11761.3585 - val_mse: 11761.3584\n",
      "Epoch 546/1000\n",
      "135/135 [==============================] - 0s 214us/sample - loss: 915.7820 - mse: 915.7820 - val_loss: 11706.5129 - val_mse: 11706.5127\n",
      "Epoch 547/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 909.9135 - mse: 909.9135 - val_loss: 11579.8649 - val_mse: 11579.8652\n",
      "Epoch 548/1000\n",
      "135/135 [==============================] - 0s 222us/sample - loss: 910.4653 - mse: 910.4653 - val_loss: 11585.9582 - val_mse: 11585.9580\n",
      "Epoch 549/1000\n",
      "135/135 [==============================] - 0s 222us/sample - loss: 908.6695 - mse: 908.6694 - val_loss: 11616.0827 - val_mse: 11616.0830\n",
      "Epoch 550/1000\n",
      "135/135 [==============================] - 0s 236us/sample - loss: 905.1230 - mse: 905.1230 - val_loss: 11636.3975 - val_mse: 11636.3975\n",
      "Epoch 551/1000\n",
      "135/135 [==============================] - 0s 222us/sample - loss: 901.9776 - mse: 901.9775 - val_loss: 11704.5069 - val_mse: 11704.5078\n",
      "Epoch 552/1000\n",
      "135/135 [==============================] - 0s 251us/sample - loss: 909.4150 - mse: 909.4150 - val_loss: 11800.1645 - val_mse: 11800.1641\n",
      "Epoch 553/1000\n",
      "135/135 [==============================] - 0s 229us/sample - loss: 916.4786 - mse: 916.4786 - val_loss: 11769.5708 - val_mse: 11769.5703\n",
      "Epoch 554/1000\n",
      "135/135 [==============================] - 0s 229us/sample - loss: 897.0013 - mse: 897.0013 - val_loss: 11841.8828 - val_mse: 11841.8828\n",
      "Epoch 555/1000\n",
      "135/135 [==============================] - 0s 222us/sample - loss: 901.8432 - mse: 901.8432 - val_loss: 11772.8019 - val_mse: 11772.8018\n",
      "Epoch 556/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 900.3922 - mse: 900.3923 - val_loss: 11660.1567 - val_mse: 11660.1562\n",
      "Epoch 557/1000\n",
      "135/135 [==============================] - 0s 214us/sample - loss: 895.9827 - mse: 895.9827 - val_loss: 11808.9439 - val_mse: 11808.9443\n",
      "Epoch 558/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 890.0517 - mse: 890.0518 - val_loss: 11772.4674 - val_mse: 11772.4668\n",
      "Epoch 559/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 890.6495 - mse: 890.6495 - val_loss: 11903.0216 - val_mse: 11903.0225\n",
      "Epoch 560/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 885.2409 - mse: 885.2408 - val_loss: 11960.0556 - val_mse: 11960.0547\n",
      "Epoch 561/1000\n",
      "135/135 [==============================] - 0s 281us/sample - loss: 895.1102 - mse: 895.1102 - val_loss: 11707.8506 - val_mse: 11707.8516\n",
      "Epoch 562/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 884.7586 - mse: 884.7587 - val_loss: 11853.8998 - val_mse: 11853.8994\n",
      "Epoch 563/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 885.1216 - mse: 885.1215 - val_loss: 11794.5855 - val_mse: 11794.5859\n",
      "Epoch 564/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 877.7052 - mse: 877.7052 - val_loss: 11722.8171 - val_mse: 11722.8174\n",
      "Epoch 565/1000\n",
      "135/135 [==============================] - 0s 163us/sample - loss: 877.3451 - mse: 877.3452 - val_loss: 11628.0988 - val_mse: 11628.0996\n",
      "Epoch 566/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 880.4641 - mse: 880.4641 - val_loss: 11553.8212 - val_mse: 11553.8213\n",
      "Epoch 567/1000\n",
      "135/135 [==============================] - 0s 163us/sample - loss: 884.2734 - mse: 884.2734 - val_loss: 11490.4233 - val_mse: 11490.4229\n",
      "Epoch 568/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 871.9750 - mse: 871.9750 - val_loss: 11647.8842 - val_mse: 11647.8838\n",
      "Epoch 569/1000\n",
      "135/135 [==============================] - 0s 163us/sample - loss: 866.2267 - mse: 866.2266 - val_loss: 11713.5340 - val_mse: 11713.5342\n",
      "Epoch 570/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 868.0430 - mse: 868.0430 - val_loss: 11721.7932 - val_mse: 11721.7930\n",
      "Epoch 571/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 870.7111 - mse: 870.7111 - val_loss: 11713.7229 - val_mse: 11713.7227\n",
      "Epoch 572/1000\n",
      "135/135 [==============================] - 0s 222us/sample - loss: 874.2077 - mse: 874.2077 - val_loss: 11848.6328 - val_mse: 11848.6328\n",
      "Epoch 573/1000\n",
      "135/135 [==============================] - 0s 222us/sample - loss: 868.3345 - mse: 868.3345 - val_loss: 11841.3980 - val_mse: 11841.3984\n",
      "Epoch 574/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 877.3150 - mse: 877.3151 - val_loss: 11751.0179 - val_mse: 11751.0186\n",
      "Epoch 575/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 864.8797 - mse: 864.8797 - val_loss: 11714.2353 - val_mse: 11714.2354\n",
      "Epoch 576/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 857.0496 - mse: 857.0497 - val_loss: 11735.8212 - val_mse: 11735.8213\n",
      "Epoch 577/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 862.1653 - mse: 862.1653 - val_loss: 11826.1976 - val_mse: 11826.1973\n",
      "Epoch 578/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 860.7382 - mse: 860.7383 - val_loss: 11828.1723 - val_mse: 11828.1729\n",
      "Epoch 579/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 855.2191 - mse: 855.2191 - val_loss: 11637.2266 - val_mse: 11637.2266\n",
      "Epoch 580/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 852.6652 - mse: 852.6653 - val_loss: 11717.0956 - val_mse: 11717.0957\n",
      "Epoch 581/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 853.7559 - mse: 853.7560 - val_loss: 11762.8153 - val_mse: 11762.8154\n",
      "Epoch 582/1000\n",
      "135/135 [==============================] - 0s 236us/sample - loss: 844.9040 - mse: 844.9040 - val_loss: 11728.2960 - val_mse: 11728.2959\n",
      "Epoch 583/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 852.2713 - mse: 852.2713 - val_loss: 11930.6291 - val_mse: 11930.6289\n",
      "Epoch 584/1000\n",
      "135/135 [==============================] - 0s 214us/sample - loss: 840.6206 - mse: 840.6206 - val_loss: 11757.9743 - val_mse: 11757.9746\n",
      "Epoch 585/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 842.8732 - mse: 842.8732 - val_loss: 11910.4099 - val_mse: 11910.4102\n",
      "Epoch 586/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 839.8259 - mse: 839.8259 - val_loss: 11839.5841 - val_mse: 11839.5850\n",
      "Epoch 587/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 840.1771 - mse: 840.1771 - val_loss: 11694.7091 - val_mse: 11694.7100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 588/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 834.1153 - mse: 834.1154 - val_loss: 11853.0464 - val_mse: 11853.0459\n",
      "Epoch 589/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 830.0255 - mse: 830.0255 - val_loss: 11958.4320 - val_mse: 11958.4316\n",
      "Epoch 590/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 833.9996 - mse: 833.9995 - val_loss: 11928.5335 - val_mse: 11928.5332\n",
      "Epoch 591/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 826.4589 - mse: 826.4588 - val_loss: 11913.9260 - val_mse: 11913.9268\n",
      "Epoch 592/1000\n",
      "135/135 [==============================] - 0s 155us/sample - loss: 829.8681 - mse: 829.8682 - val_loss: 11996.5455 - val_mse: 11996.5459\n",
      "Epoch 593/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 838.1907 - mse: 838.1907 - val_loss: 11948.1815 - val_mse: 11948.1816\n",
      "Epoch 594/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 823.7835 - mse: 823.7835 - val_loss: 11726.6296 - val_mse: 11726.6299\n",
      "Epoch 595/1000\n",
      "135/135 [==============================] - 0s 163us/sample - loss: 824.0610 - mse: 824.0610 - val_loss: 11774.7413 - val_mse: 11774.7412\n",
      "Epoch 596/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 823.1751 - mse: 823.1751 - val_loss: 11835.3474 - val_mse: 11835.3477\n",
      "Epoch 597/1000\n",
      "135/135 [==============================] - 0s 163us/sample - loss: 822.1123 - mse: 822.1123 - val_loss: 11966.4784 - val_mse: 11966.4775\n",
      "Epoch 598/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 816.0879 - mse: 816.0880 - val_loss: 11902.6438 - val_mse: 11902.6436\n",
      "Epoch 599/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 817.2947 - mse: 817.2947 - val_loss: 11944.3235 - val_mse: 11944.3232\n",
      "Epoch 600/1000\n",
      "135/135 [==============================] - 0s 163us/sample - loss: 814.9174 - mse: 814.9174 - val_loss: 11886.6912 - val_mse: 11886.6914\n",
      "Epoch 601/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 815.4142 - mse: 815.4142 - val_loss: 12006.8456 - val_mse: 12006.8457\n",
      "Epoch 602/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 814.7387 - mse: 814.7387 - val_loss: 11951.7555 - val_mse: 11951.7559\n",
      "Epoch 603/1000\n",
      "135/135 [==============================] - 0s 163us/sample - loss: 814.4411 - mse: 814.4412 - val_loss: 11842.5271 - val_mse: 11842.5273\n",
      "Epoch 604/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 805.7034 - mse: 805.7035 - val_loss: 11974.9517 - val_mse: 11974.9521\n",
      "Epoch 605/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 803.0703 - mse: 803.0702 - val_loss: 11960.0418 - val_mse: 11960.0420\n",
      "Epoch 606/1000\n",
      "135/135 [==============================] - 0s 162us/sample - loss: 809.6173 - mse: 809.6172 - val_loss: 12079.7721 - val_mse: 12079.7725\n",
      "Epoch 607/1000\n",
      "135/135 [==============================] - 0s 163us/sample - loss: 804.8484 - mse: 804.8484 - val_loss: 11962.4187 - val_mse: 11962.4189\n",
      "Epoch 608/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 796.5826 - mse: 796.5826 - val_loss: 11951.0758 - val_mse: 11951.0752\n",
      "Epoch 609/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 798.2868 - mse: 798.2868 - val_loss: 11885.1618 - val_mse: 11885.1621\n",
      "Epoch 610/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 796.2747 - mse: 796.2747 - val_loss: 11857.4237 - val_mse: 11857.4238\n",
      "Epoch 611/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 811.6855 - mse: 811.6855 - val_loss: 11871.2528 - val_mse: 11871.2529\n",
      "Epoch 612/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 790.5850 - mse: 790.5850 - val_loss: 11931.9752 - val_mse: 11931.9756\n",
      "Epoch 613/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 790.7251 - mse: 790.7250 - val_loss: 11945.4550 - val_mse: 11945.4551\n",
      "Epoch 614/1000\n",
      "135/135 [==============================] - 0s 222us/sample - loss: 784.9085 - mse: 784.9085 - val_loss: 12058.4136 - val_mse: 12058.4141\n",
      "Epoch 615/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 792.8732 - mse: 792.8732 - val_loss: 12119.2031 - val_mse: 12119.2031\n",
      "Epoch 616/1000\n",
      "135/135 [==============================] - 0s 214us/sample - loss: 789.4951 - mse: 789.4950 - val_loss: 12071.0827 - val_mse: 12071.0830\n",
      "Epoch 617/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 779.3523 - mse: 779.3523 - val_loss: 12008.5129 - val_mse: 12008.5127\n",
      "Epoch 618/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 775.7781 - mse: 775.7781 - val_loss: 12006.5887 - val_mse: 12006.5879\n",
      "Epoch 619/1000\n",
      "135/135 [==============================] - 0s 163us/sample - loss: 781.2290 - mse: 781.2290 - val_loss: 11980.0666 - val_mse: 11980.0664\n",
      "Epoch 620/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 772.3836 - mse: 772.3837 - val_loss: 12201.4715 - val_mse: 12201.4717\n",
      "Epoch 621/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 778.9521 - mse: 778.9521 - val_loss: 12113.6958 - val_mse: 12113.6953\n",
      "Epoch 622/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 771.6763 - mse: 771.6763 - val_loss: 12159.5666 - val_mse: 12159.5664\n",
      "Epoch 623/1000\n",
      "135/135 [==============================] - 0s 163us/sample - loss: 772.1779 - mse: 772.1779 - val_loss: 12253.7505 - val_mse: 12253.7500\n",
      "Epoch 624/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 770.5860 - mse: 770.5861 - val_loss: 12248.1255 - val_mse: 12248.1250\n",
      "Epoch 625/1000\n",
      "135/135 [==============================] - 0s 155us/sample - loss: 767.2584 - mse: 767.2584 - val_loss: 12147.8456 - val_mse: 12147.8457\n",
      "Epoch 626/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 769.4276 - mse: 769.4276 - val_loss: 11941.8387 - val_mse: 11941.8379\n",
      "Epoch 627/1000\n",
      "135/135 [==============================] - 0s 222us/sample - loss: 763.1091 - mse: 763.1091 - val_loss: 12040.1567 - val_mse: 12040.1562\n",
      "Epoch 628/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 757.7602 - mse: 757.7602 - val_loss: 12164.7840 - val_mse: 12164.7842\n",
      "Epoch 629/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 774.6160 - mse: 774.6160 - val_loss: 12161.2606 - val_mse: 12161.2607\n",
      "Epoch 630/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 760.9717 - mse: 760.9717 - val_loss: 12157.2633 - val_mse: 12157.2627\n",
      "Epoch 631/1000\n",
      "135/135 [==============================] - 0s 163us/sample - loss: 751.5687 - mse: 751.5687 - val_loss: 12099.9108 - val_mse: 12099.9111\n",
      "Epoch 632/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 754.6214 - mse: 754.6214 - val_loss: 12104.7684 - val_mse: 12104.7686\n",
      "Epoch 633/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 751.3232 - mse: 751.3231 - val_loss: 12074.7339 - val_mse: 12074.7334\n",
      "Epoch 634/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 754.7353 - mse: 754.7354 - val_loss: 12255.1149 - val_mse: 12255.1152\n",
      "Epoch 635/1000\n",
      "135/135 [==============================] - 0s 157us/sample - loss: 753.0594 - mse: 753.0594 - val_loss: 12251.5956 - val_mse: 12251.5957\n",
      "Epoch 636/1000\n",
      "135/135 [==============================] - 0s 168us/sample - loss: 749.3131 - mse: 749.3131 - val_loss: 12032.0974 - val_mse: 12032.0977\n",
      "Epoch 637/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 745.8923 - mse: 745.8923 - val_loss: 11923.7946 - val_mse: 11923.7939\n",
      "Epoch 638/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 745.1133 - mse: 745.1133 - val_loss: 11942.6705 - val_mse: 11942.6709\n",
      "Epoch 639/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 739.7544 - mse: 739.7544 - val_loss: 11927.0064 - val_mse: 11927.0068\n",
      "Epoch 640/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 742.8966 - mse: 742.8967 - val_loss: 12170.7390 - val_mse: 12170.7393\n",
      "Epoch 641/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 744.5995 - mse: 744.5994 - val_loss: 12158.5358 - val_mse: 12158.5361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 642/1000\n",
      "135/135 [==============================] - 0s 184us/sample - loss: 733.6787 - mse: 733.6787 - val_loss: 12161.5051 - val_mse: 12161.5059\n",
      "Epoch 643/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 741.2918 - mse: 741.2918 - val_loss: 12224.4779 - val_mse: 12224.4775\n",
      "Epoch 644/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 734.9625 - mse: 734.9625 - val_loss: 12099.5731 - val_mse: 12099.5732\n",
      "Epoch 645/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 735.9812 - mse: 735.9813 - val_loss: 12118.6328 - val_mse: 12118.6328\n",
      "Epoch 646/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 727.4310 - mse: 727.4310 - val_loss: 11941.3585 - val_mse: 11941.3584\n",
      "Epoch 647/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 729.5217 - mse: 729.5218 - val_loss: 12146.5345 - val_mse: 12146.5352\n",
      "Epoch 648/1000\n",
      "135/135 [==============================] - 0s 214us/sample - loss: 734.3423 - mse: 734.3422 - val_loss: 12207.8396 - val_mse: 12207.8398\n",
      "Epoch 649/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 727.5725 - mse: 727.5725 - val_loss: 11967.3750 - val_mse: 11967.3750\n",
      "Epoch 650/1000\n",
      "135/135 [==============================] - 0s 229us/sample - loss: 722.6406 - mse: 722.6406 - val_loss: 11849.2073 - val_mse: 11849.2080\n",
      "Epoch 651/1000\n",
      "135/135 [==============================] - 0s 214us/sample - loss: 720.1031 - mse: 720.1031 - val_loss: 11945.6195 - val_mse: 11945.6191\n",
      "Epoch 652/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 712.7527 - mse: 712.7528 - val_loss: 11985.8387 - val_mse: 11985.8379\n",
      "Epoch 653/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 722.6967 - mse: 722.6968 - val_loss: 12276.4283 - val_mse: 12276.4287\n",
      "Epoch 654/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 723.0211 - mse: 723.0211 - val_loss: 12237.0625 - val_mse: 12237.0625\n",
      "Epoch 655/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 711.5928 - mse: 711.5928 - val_loss: 12231.6232 - val_mse: 12231.6230\n",
      "Epoch 656/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 717.8021 - mse: 717.8021 - val_loss: 12149.2941 - val_mse: 12149.2939\n",
      "Epoch 657/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 718.2568 - mse: 718.2568 - val_loss: 12118.0712 - val_mse: 12118.0713\n",
      "Epoch 658/1000\n",
      "135/135 [==============================] - 0s 214us/sample - loss: 719.8916 - mse: 719.8916 - val_loss: 12228.7578 - val_mse: 12228.7578\n",
      "Epoch 659/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 712.6882 - mse: 712.6882 - val_loss: 12047.7785 - val_mse: 12047.7783\n",
      "Epoch 660/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 705.5277 - mse: 705.5277 - val_loss: 12048.5064 - val_mse: 12048.5068\n",
      "Epoch 661/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 704.5325 - mse: 704.5325 - val_loss: 12186.0813 - val_mse: 12186.0811\n",
      "Epoch 662/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 705.5111 - mse: 705.5110 - val_loss: 12340.4122 - val_mse: 12340.4121\n",
      "Epoch 663/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 699.0589 - mse: 699.0589 - val_loss: 12292.7243 - val_mse: 12292.7246\n",
      "Epoch 664/1000\n",
      "135/135 [==============================] - 0s 221us/sample - loss: 701.4318 - mse: 701.4318 - val_loss: 12053.9596 - val_mse: 12053.9600\n",
      "Epoch 665/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 697.0889 - mse: 697.0889 - val_loss: 12224.8208 - val_mse: 12224.8203\n",
      "Epoch 666/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 702.0831 - mse: 702.0831 - val_loss: 12200.0574 - val_mse: 12200.0566\n",
      "Epoch 667/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 698.7618 - mse: 698.7618 - val_loss: 12147.8033 - val_mse: 12147.8037\n",
      "Epoch 668/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 697.4640 - mse: 697.4640 - val_loss: 11945.0496 - val_mse: 11945.0498\n",
      "Epoch 669/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 697.5150 - mse: 697.5150 - val_loss: 12258.3341 - val_mse: 12258.3350\n",
      "Epoch 670/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 691.3386 - mse: 691.3386 - val_loss: 12354.2992 - val_mse: 12354.2998\n",
      "Epoch 671/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 689.6596 - mse: 689.6596 - val_loss: 12308.9159 - val_mse: 12308.9150\n",
      "Epoch 672/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 685.9411 - mse: 685.9412 - val_loss: 12315.7151 - val_mse: 12315.7148\n",
      "Epoch 673/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 685.0084 - mse: 685.0084 - val_loss: 12296.5997 - val_mse: 12296.5996\n",
      "Epoch 674/1000\n",
      "135/135 [==============================] - 0s 163us/sample - loss: 684.4124 - mse: 684.4124 - val_loss: 12091.7394 - val_mse: 12091.7393\n",
      "Epoch 675/1000\n",
      "135/135 [==============================] - 0s 163us/sample - loss: 682.2090 - mse: 682.2090 - val_loss: 12156.9591 - val_mse: 12156.9600\n",
      "Epoch 676/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 675.4204 - mse: 675.4203 - val_loss: 12248.2707 - val_mse: 12248.2705\n",
      "Epoch 677/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 688.6897 - mse: 688.6897 - val_loss: 12253.0960 - val_mse: 12253.0957\n",
      "Epoch 678/1000\n",
      "135/135 [==============================] - 0s 214us/sample - loss: 692.2775 - mse: 692.2775 - val_loss: 12266.2523 - val_mse: 12266.2520\n",
      "Epoch 679/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 680.6687 - mse: 680.6688 - val_loss: 12198.7638 - val_mse: 12198.7637\n",
      "Epoch 680/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 677.4106 - mse: 677.4106 - val_loss: 12250.2849 - val_mse: 12250.2852\n",
      "Epoch 681/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 676.2069 - mse: 676.2068 - val_loss: 12210.0349 - val_mse: 12210.0352\n",
      "Epoch 682/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 676.7656 - mse: 676.7656 - val_loss: 12158.6737 - val_mse: 12158.6738\n",
      "Epoch 683/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 665.4423 - mse: 665.4424 - val_loss: 12196.6650 - val_mse: 12196.6650\n",
      "Epoch 684/1000\n",
      "135/135 [==============================] - 0s 222us/sample - loss: 666.3990 - mse: 666.3990 - val_loss: 12252.1250 - val_mse: 12252.1250\n",
      "Epoch 685/1000\n",
      "135/135 [==============================] - 0s 222us/sample - loss: 679.0721 - mse: 679.0721 - val_loss: 12259.6048 - val_mse: 12259.6045\n",
      "Epoch 686/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 661.5259 - mse: 661.5259 - val_loss: 12331.9251 - val_mse: 12331.9248\n",
      "Epoch 687/1000\n",
      "135/135 [==============================] - 0s 214us/sample - loss: 666.2882 - mse: 666.2882 - val_loss: 12368.0882 - val_mse: 12368.0879\n",
      "Epoch 688/1000\n",
      "135/135 [==============================] - 0s 214us/sample - loss: 665.2928 - mse: 665.2928 - val_loss: 12351.5455 - val_mse: 12351.5459\n",
      "Epoch 689/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 655.7008 - mse: 655.7008 - val_loss: 12192.8061 - val_mse: 12192.8057\n",
      "Epoch 690/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 660.8540 - mse: 660.8540 - val_loss: 12315.5335 - val_mse: 12315.5332\n",
      "Epoch 691/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 662.8559 - mse: 662.8559 - val_loss: 12313.8267 - val_mse: 12313.8271\n",
      "Epoch 692/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 652.0651 - mse: 652.0652 - val_loss: 12352.7725 - val_mse: 12352.7725\n",
      "Epoch 693/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 662.2185 - mse: 662.2184 - val_loss: 12413.0211 - val_mse: 12413.0215\n",
      "Epoch 694/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 655.3992 - mse: 655.3991 - val_loss: 12286.6163 - val_mse: 12286.6162\n",
      "Epoch 695/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 646.9613 - mse: 646.9613 - val_loss: 12230.5294 - val_mse: 12230.5293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 696/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 650.8020 - mse: 650.8019 - val_loss: 12271.4858 - val_mse: 12271.4854\n",
      "Epoch 697/1000\n",
      "135/135 [==============================] - 0s 155us/sample - loss: 647.4755 - mse: 647.4755 - val_loss: 12370.9913 - val_mse: 12370.9912\n",
      "Epoch 698/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 658.0246 - mse: 658.0246 - val_loss: 12368.4825 - val_mse: 12368.4824\n",
      "Epoch 699/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 650.2240 - mse: 650.2240 - val_loss: 12245.7518 - val_mse: 12245.7520\n",
      "Epoch 700/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 649.4011 - mse: 649.4011 - val_loss: 12428.3589 - val_mse: 12428.3584\n",
      "Epoch 701/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 643.7551 - mse: 643.7551 - val_loss: 12303.2780 - val_mse: 12303.2773\n",
      "Epoch 702/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 640.4393 - mse: 640.4393 - val_loss: 12338.0859 - val_mse: 12338.0859\n",
      "Epoch 703/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 640.7217 - mse: 640.7216 - val_loss: 12388.6080 - val_mse: 12388.6084\n",
      "Epoch 704/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 635.8501 - mse: 635.8501 - val_loss: 12353.6792 - val_mse: 12353.6797\n",
      "Epoch 705/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 636.6946 - mse: 636.6946 - val_loss: 12368.4715 - val_mse: 12368.4717\n",
      "Epoch 706/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 640.7346 - mse: 640.7346 - val_loss: 12437.6108 - val_mse: 12437.6104\n",
      "Epoch 707/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 635.7358 - mse: 635.7358 - val_loss: 12482.6213 - val_mse: 12482.6211\n",
      "Epoch 708/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 631.1828 - mse: 631.1828 - val_loss: 12462.4462 - val_mse: 12462.4463\n",
      "Epoch 709/1000\n",
      "135/135 [==============================] - 0s 163us/sample - loss: 630.2343 - mse: 630.2343 - val_loss: 12530.2399 - val_mse: 12530.2402\n",
      "Epoch 710/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 632.8189 - mse: 632.8188 - val_loss: 12541.3286 - val_mse: 12541.3291\n",
      "Epoch 711/1000\n",
      "135/135 [==============================] - 0s 180us/sample - loss: 628.9901 - mse: 628.9901 - val_loss: 12467.7096 - val_mse: 12467.7100\n",
      "Epoch 712/1000\n",
      "135/135 [==============================] - 0s 155us/sample - loss: 631.3564 - mse: 631.3564 - val_loss: 12225.2716 - val_mse: 12225.2725\n",
      "Epoch 713/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 622.1585 - mse: 622.1585 - val_loss: 12316.3635 - val_mse: 12316.3643\n",
      "Epoch 714/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 621.1719 - mse: 621.1719 - val_loss: 12447.0749 - val_mse: 12447.0752\n",
      "Epoch 715/1000\n",
      "135/135 [==============================] - 0s 229us/sample - loss: 622.2011 - mse: 622.2011 - val_loss: 12418.2509 - val_mse: 12418.2510\n",
      "Epoch 716/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 620.8629 - mse: 620.8629 - val_loss: 12328.7923 - val_mse: 12328.7920\n",
      "Epoch 717/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 617.9390 - mse: 617.9390 - val_loss: 12406.9159 - val_mse: 12406.9150\n",
      "Epoch 718/1000\n",
      "135/135 [==============================] - 0s 266us/sample - loss: 620.3104 - mse: 620.3104 - val_loss: 12328.9150 - val_mse: 12328.9150\n",
      "Epoch 719/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 616.1680 - mse: 616.1680 - val_loss: 12226.4743 - val_mse: 12226.4746\n",
      "Epoch 720/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 609.8026 - mse: 609.8026 - val_loss: 12257.2955 - val_mse: 12257.2959\n",
      "Epoch 721/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 617.5852 - mse: 617.5852 - val_loss: 12385.2840 - val_mse: 12385.2842\n",
      "Epoch 722/1000\n",
      "135/135 [==============================] - 0s 155us/sample - loss: 607.4710 - mse: 607.4710 - val_loss: 12408.1728 - val_mse: 12408.1729\n",
      "Epoch 723/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 608.5236 - mse: 608.5236 - val_loss: 12353.0083 - val_mse: 12353.0078\n",
      "Epoch 724/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 612.3124 - mse: 612.3124 - val_loss: 12258.6080 - val_mse: 12258.6084\n",
      "Epoch 725/1000\n",
      "135/135 [==============================] - 0s 190us/sample - loss: 610.0983 - mse: 610.0983 - val_loss: 12387.4802 - val_mse: 12387.4795\n",
      "Epoch 726/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 606.8198 - mse: 606.8198 - val_loss: 12209.1016 - val_mse: 12209.1016\n",
      "Epoch 727/1000\n",
      "135/135 [==============================] - 0s 162us/sample - loss: 601.8321 - mse: 601.8322 - val_loss: 12287.9807 - val_mse: 12287.9805\n",
      "Epoch 728/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 603.5346 - mse: 603.5346 - val_loss: 12380.4628 - val_mse: 12380.4629\n",
      "Epoch 729/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 601.5821 - mse: 601.5821 - val_loss: 12353.8277 - val_mse: 12353.8271\n",
      "Epoch 730/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 597.1139 - mse: 597.1139 - val_loss: 12300.1884 - val_mse: 12300.1885\n",
      "Epoch 731/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 602.4768 - mse: 602.4768 - val_loss: 12461.6360 - val_mse: 12461.6357\n",
      "Epoch 732/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 604.9296 - mse: 604.9296 - val_loss: 12509.0087 - val_mse: 12509.0088\n",
      "Epoch 733/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 601.4532 - mse: 601.4532 - val_loss: 12452.7854 - val_mse: 12452.7852\n",
      "Epoch 734/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 597.1184 - mse: 597.1184 - val_loss: 12175.3888 - val_mse: 12175.3887\n",
      "Epoch 735/1000\n",
      "135/135 [==============================] - 0s 214us/sample - loss: 603.4072 - mse: 603.4072 - val_loss: 12215.3566 - val_mse: 12215.3564\n",
      "Epoch 736/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 593.7609 - mse: 593.7608 - val_loss: 12242.1434 - val_mse: 12242.1436\n",
      "Epoch 737/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 589.7325 - mse: 589.7325 - val_loss: 12379.8713 - val_mse: 12379.8711\n",
      "Epoch 738/1000\n",
      "135/135 [==============================] - 0s 214us/sample - loss: 590.6214 - mse: 590.6214 - val_loss: 12380.8516 - val_mse: 12380.8516\n",
      "Epoch 739/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 596.5624 - mse: 596.5624 - val_loss: 12488.4628 - val_mse: 12488.4629\n",
      "Epoch 740/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 592.9808 - mse: 592.9808 - val_loss: 12432.9278 - val_mse: 12432.9287\n",
      "Epoch 741/1000\n",
      "135/135 [==============================] - 0s 169us/sample - loss: 581.1430 - mse: 581.1430 - val_loss: 12121.4963 - val_mse: 12121.4961\n",
      "Epoch 742/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 580.2255 - mse: 580.2256 - val_loss: 12230.6006 - val_mse: 12230.6016\n",
      "Epoch 743/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 584.2871 - mse: 584.2871 - val_loss: 12237.2776 - val_mse: 12237.2773\n",
      "Epoch 744/1000\n",
      "135/135 [==============================] - 0s 163us/sample - loss: 582.1883 - mse: 582.1883 - val_loss: 12265.9825 - val_mse: 12265.9824\n",
      "Epoch 745/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 576.3913 - mse: 576.3913 - val_loss: 12391.9504 - val_mse: 12391.9502\n",
      "Epoch 746/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 577.3905 - mse: 577.3905 - val_loss: 12459.0165 - val_mse: 12459.0166\n",
      "Epoch 747/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 576.6309 - mse: 576.6309 - val_loss: 12386.4775 - val_mse: 12386.4775\n",
      "Epoch 748/1000\n",
      "135/135 [==============================] - 0s 163us/sample - loss: 580.5415 - mse: 580.5415 - val_loss: 12497.8594 - val_mse: 12497.8594\n",
      "Epoch 749/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 570.2720 - mse: 570.2720 - val_loss: 12542.0951 - val_mse: 12542.0957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 750/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 569.7255 - mse: 569.7255 - val_loss: 12617.7702 - val_mse: 12617.7705\n",
      "Epoch 751/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 574.2918 - mse: 574.2918 - val_loss: 12534.2996 - val_mse: 12534.2998\n",
      "Epoch 752/1000\n",
      "135/135 [==============================] - 0s 162us/sample - loss: 574.1108 - mse: 574.1108 - val_loss: 12271.7059 - val_mse: 12271.7061\n",
      "Epoch 753/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 568.1610 - mse: 568.1610 - val_loss: 12320.0299 - val_mse: 12320.0293\n",
      "Epoch 754/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 574.3183 - mse: 574.3184 - val_loss: 12392.9596 - val_mse: 12392.9600\n",
      "Epoch 755/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 562.0190 - mse: 562.0190 - val_loss: 12394.8681 - val_mse: 12394.8672\n",
      "Epoch 756/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 569.8193 - mse: 569.8193 - val_loss: 12576.1172 - val_mse: 12576.1172\n",
      "Epoch 757/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 560.9164 - mse: 560.9164 - val_loss: 12502.7656 - val_mse: 12502.7656\n",
      "Epoch 758/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 559.5916 - mse: 559.5916 - val_loss: 12403.7960 - val_mse: 12403.7959\n",
      "Epoch 759/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 564.2439 - mse: 564.2439 - val_loss: 12558.1847 - val_mse: 12558.1846\n",
      "Epoch 760/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 556.5253 - mse: 556.5253 - val_loss: 12408.0910 - val_mse: 12408.0908\n",
      "Epoch 761/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 556.8084 - mse: 556.8083 - val_loss: 12417.7192 - val_mse: 12417.7188\n",
      "Epoch 762/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 562.5775 - mse: 562.5775 - val_loss: 12350.6489 - val_mse: 12350.6484\n",
      "Epoch 763/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 560.9436 - mse: 560.9436 - val_loss: 12387.8897 - val_mse: 12387.8896\n",
      "Epoch 764/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 561.3037 - mse: 561.3037 - val_loss: 12342.1838 - val_mse: 12342.1836\n",
      "Epoch 765/1000\n",
      "135/135 [==============================] - 0s 163us/sample - loss: 553.3126 - mse: 553.3126 - val_loss: 12507.7063 - val_mse: 12507.7061\n",
      "Epoch 766/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 556.5268 - mse: 556.5269 - val_loss: 12454.6365 - val_mse: 12454.6357\n",
      "Epoch 767/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 550.9785 - mse: 550.9785 - val_loss: 12455.3543 - val_mse: 12455.3545\n",
      "Epoch 768/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 555.1247 - mse: 555.1247 - val_loss: 12626.7555 - val_mse: 12626.7559\n",
      "Epoch 769/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 549.5748 - mse: 549.5747 - val_loss: 12514.7146 - val_mse: 12514.7148\n",
      "Epoch 770/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 541.9961 - mse: 541.9961 - val_loss: 12472.3139 - val_mse: 12472.3145\n",
      "Epoch 771/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 552.3453 - mse: 552.3454 - val_loss: 12493.4752 - val_mse: 12493.4756\n",
      "Epoch 772/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 545.4622 - mse: 545.4622 - val_loss: 12385.1549 - val_mse: 12385.1543\n",
      "Epoch 773/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 540.8205 - mse: 540.8204 - val_loss: 12289.4554 - val_mse: 12289.4561\n",
      "Epoch 774/1000\n",
      "135/135 [==============================] - 0s 162us/sample - loss: 546.0727 - mse: 546.0727 - val_loss: 12474.1949 - val_mse: 12474.1953\n",
      "Epoch 775/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 540.1060 - mse: 540.1060 - val_loss: 12594.1930 - val_mse: 12594.1934\n",
      "Epoch 776/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 542.3174 - mse: 542.3174 - val_loss: 12529.6861 - val_mse: 12529.6855\n",
      "Epoch 777/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 538.9986 - mse: 538.9986 - val_loss: 12412.5395 - val_mse: 12412.5391\n",
      "Epoch 778/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 538.7432 - mse: 538.7432 - val_loss: 12622.8143 - val_mse: 12622.8145\n",
      "Epoch 779/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 541.6302 - mse: 541.6302 - val_loss: 12580.3451 - val_mse: 12580.3457\n",
      "Epoch 780/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 537.7756 - mse: 537.7756 - val_loss: 12541.0662 - val_mse: 12541.0664\n",
      "Epoch 781/1000\n",
      "135/135 [==============================] - 0s 183us/sample - loss: 534.1236 - mse: 534.1236 - val_loss: 12431.1328 - val_mse: 12431.1328\n",
      "Epoch 782/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 525.7814 - mse: 525.7814 - val_loss: 12239.6916 - val_mse: 12239.6914\n",
      "Epoch 783/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 532.2676 - mse: 532.2676 - val_loss: 12397.9154 - val_mse: 12397.9150\n",
      "Epoch 784/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 530.2234 - mse: 530.2233 - val_loss: 12400.8277 - val_mse: 12400.8271\n",
      "Epoch 785/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 524.9528 - mse: 524.9528 - val_loss: 12459.3028 - val_mse: 12459.3037\n",
      "Epoch 786/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 529.9517 - mse: 529.9517 - val_loss: 12494.7941 - val_mse: 12494.7939\n",
      "Epoch 787/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 521.1397 - mse: 521.1397 - val_loss: 12475.1163 - val_mse: 12475.1162\n",
      "Epoch 788/1000\n",
      "135/135 [==============================] - 0s 159us/sample - loss: 524.1868 - mse: 524.1868 - val_loss: 12413.7266 - val_mse: 12413.7266\n",
      "Epoch 789/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 517.9344 - mse: 517.9344 - val_loss: 12301.7358 - val_mse: 12301.7354\n",
      "Epoch 790/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 526.4183 - mse: 526.4183 - val_loss: 12370.5074 - val_mse: 12370.5078\n",
      "Epoch 791/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 523.1953 - mse: 523.1953 - val_loss: 12504.3938 - val_mse: 12504.3936\n",
      "Epoch 792/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 517.8858 - mse: 517.8857 - val_loss: 12421.7151 - val_mse: 12421.7148\n",
      "Epoch 793/1000\n",
      "135/135 [==============================] - 0s 200us/sample - loss: 510.8034 - mse: 510.8033 - val_loss: 12559.7137 - val_mse: 12559.7129\n",
      "Epoch 794/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 514.9856 - mse: 514.9856 - val_loss: 12316.5749 - val_mse: 12316.5752\n",
      "Epoch 795/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 511.6324 - mse: 511.6324 - val_loss: 12410.1590 - val_mse: 12410.1592\n",
      "Epoch 796/1000\n",
      "135/135 [==============================] - 0s 163us/sample - loss: 518.8518 - mse: 518.8518 - val_loss: 12635.1402 - val_mse: 12635.1396\n",
      "Epoch 797/1000\n",
      "135/135 [==============================] - 0s 244us/sample - loss: 519.9767 - mse: 519.9767 - val_loss: 12625.5639 - val_mse: 12625.5645\n",
      "Epoch 798/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 508.7011 - mse: 508.7011 - val_loss: 12309.2509 - val_mse: 12309.2510\n",
      "Epoch 799/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 516.0536 - mse: 516.0536 - val_loss: 12560.5983 - val_mse: 12560.5986\n",
      "Epoch 800/1000\n",
      "135/135 [==============================] - 0s 273us/sample - loss: 513.3719 - mse: 513.3720 - val_loss: 12659.8217 - val_mse: 12659.8213\n",
      "Epoch 801/1000\n",
      "135/135 [==============================] - 0s 236us/sample - loss: 511.2547 - mse: 511.2547 - val_loss: 12617.8382 - val_mse: 12617.8379\n",
      "Epoch 802/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 506.6139 - mse: 506.6140 - val_loss: 12447.0602 - val_mse: 12447.0605\n",
      "Epoch 803/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 511.5340 - mse: 511.5341 - val_loss: 12403.0051 - val_mse: 12403.0059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 804/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 505.9559 - mse: 505.9559 - val_loss: 12438.6108 - val_mse: 12438.6104\n",
      "Epoch 805/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 513.5870 - mse: 513.5870 - val_loss: 12618.3704 - val_mse: 12618.3701\n",
      "Epoch 806/1000\n",
      "135/135 [==============================] - 0s 163us/sample - loss: 502.3294 - mse: 502.3294 - val_loss: 12616.7408 - val_mse: 12616.7412\n",
      "Epoch 807/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 503.7108 - mse: 503.7108 - val_loss: 12514.7592 - val_mse: 12514.7588\n",
      "Epoch 808/1000\n",
      "135/135 [==============================] - 0s 214us/sample - loss: 502.4242 - mse: 502.4243 - val_loss: 12523.5138 - val_mse: 12523.5137\n",
      "Epoch 809/1000\n",
      "135/135 [==============================] - 0s 222us/sample - loss: 495.6803 - mse: 495.6803 - val_loss: 12336.6218 - val_mse: 12336.6211\n",
      "Epoch 810/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 497.6073 - mse: 497.6072 - val_loss: 12507.2284 - val_mse: 12507.2275\n",
      "Epoch 811/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 500.2016 - mse: 500.2016 - val_loss: 12477.8097 - val_mse: 12477.8096\n",
      "Epoch 812/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 501.7449 - mse: 501.7448 - val_loss: 12315.7137 - val_mse: 12315.7129\n",
      "Epoch 813/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 501.8555 - mse: 501.8555 - val_loss: 12317.6857 - val_mse: 12317.6855\n",
      "Epoch 814/1000\n",
      "135/135 [==============================] - 0s 222us/sample - loss: 495.3654 - mse: 495.3653 - val_loss: 12498.2243 - val_mse: 12498.2246\n",
      "Epoch 815/1000\n",
      "135/135 [==============================] - 0s 236us/sample - loss: 488.9781 - mse: 488.9781 - val_loss: 12207.7904 - val_mse: 12207.7900\n",
      "Epoch 816/1000\n",
      "135/135 [==============================] - 0s 214us/sample - loss: 486.9073 - mse: 486.9073 - val_loss: 12219.7578 - val_mse: 12219.7578\n",
      "Epoch 817/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 489.3042 - mse: 489.3042 - val_loss: 12459.6466 - val_mse: 12459.6475\n",
      "Epoch 818/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 488.4042 - mse: 488.4042 - val_loss: 12389.2114 - val_mse: 12389.2109\n",
      "Epoch 819/1000\n",
      "135/135 [==============================] - 0s 214us/sample - loss: 489.8348 - mse: 489.8348 - val_loss: 12391.2210 - val_mse: 12391.2207\n",
      "Epoch 820/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 484.0584 - mse: 484.0584 - val_loss: 12275.5455 - val_mse: 12275.5459\n",
      "Epoch 821/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 481.8478 - mse: 481.8479 - val_loss: 12491.5156 - val_mse: 12491.5156\n",
      "Epoch 822/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 494.5482 - mse: 494.5482 - val_loss: 12682.0202 - val_mse: 12682.0205\n",
      "Epoch 823/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 495.6414 - mse: 495.6414 - val_loss: 12505.0230 - val_mse: 12505.0234\n",
      "Epoch 824/1000\n",
      "135/135 [==============================] - 0s 200us/sample - loss: 486.6434 - mse: 486.6434 - val_loss: 12441.5951 - val_mse: 12441.5957\n",
      "Epoch 825/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 486.9522 - mse: 486.9522 - val_loss: 12493.8327 - val_mse: 12493.8330\n",
      "Epoch 826/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 477.4200 - mse: 477.4200 - val_loss: 12592.5712 - val_mse: 12592.5713\n",
      "Epoch 827/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 485.3963 - mse: 485.3964 - val_loss: 12483.8300 - val_mse: 12483.8301\n",
      "Epoch 828/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 478.8287 - mse: 478.8287 - val_loss: 12327.8589 - val_mse: 12327.8584\n",
      "Epoch 829/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 477.5497 - mse: 477.5497 - val_loss: 12359.2210 - val_mse: 12359.2207\n",
      "Epoch 830/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 478.3037 - mse: 478.3037 - val_loss: 12308.8438 - val_mse: 12308.8438\n",
      "Epoch 831/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 475.4739 - mse: 475.4739 - val_loss: 12678.0942 - val_mse: 12678.0938\n",
      "Epoch 832/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 473.8262 - mse: 473.8262 - val_loss: 12583.7284 - val_mse: 12583.7275\n",
      "Epoch 833/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 474.1221 - mse: 474.1221 - val_loss: 12645.6521 - val_mse: 12645.6523\n",
      "Epoch 834/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 469.1148 - mse: 469.1148 - val_loss: 12629.8713 - val_mse: 12629.8711\n",
      "Epoch 835/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 478.2844 - mse: 478.2845 - val_loss: 12359.1903 - val_mse: 12359.1904\n",
      "Epoch 836/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 469.9678 - mse: 469.9678 - val_loss: 12218.0722 - val_mse: 12218.0713\n",
      "Epoch 837/1000\n",
      "135/135 [==============================] - 0s 155us/sample - loss: 468.3364 - mse: 468.3364 - val_loss: 12274.9646 - val_mse: 12274.9648\n",
      "Epoch 838/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 472.5863 - mse: 472.5863 - val_loss: 12327.6687 - val_mse: 12327.6689\n",
      "Epoch 839/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 470.5239 - mse: 470.5239 - val_loss: 12457.3258 - val_mse: 12457.3252\n",
      "Epoch 840/1000\n",
      "135/135 [==============================] - 0s 163us/sample - loss: 473.5221 - mse: 473.5220 - val_loss: 12248.9265 - val_mse: 12248.9268\n",
      "Epoch 841/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 465.3468 - mse: 465.3468 - val_loss: 12411.5607 - val_mse: 12411.5605\n",
      "Epoch 842/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 461.2614 - mse: 461.2614 - val_loss: 12418.6549 - val_mse: 12418.6543\n",
      "Epoch 843/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 471.6338 - mse: 471.6338 - val_loss: 12481.9444 - val_mse: 12481.9453\n",
      "Epoch 844/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 454.0334 - mse: 454.0334 - val_loss: 12453.2560 - val_mse: 12453.2559\n",
      "Epoch 845/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 460.1492 - mse: 460.1492 - val_loss: 12227.1622 - val_mse: 12227.1621\n",
      "Epoch 846/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 454.0474 - mse: 454.0474 - val_loss: 12461.2040 - val_mse: 12461.2041\n",
      "Epoch 847/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 460.2108 - mse: 460.2108 - val_loss: 12244.8277 - val_mse: 12244.8271\n",
      "Epoch 848/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 459.5648 - mse: 459.5648 - val_loss: 12339.7408 - val_mse: 12339.7412\n",
      "Epoch 849/1000\n",
      "135/135 [==============================] - 0s 163us/sample - loss: 449.4736 - mse: 449.4736 - val_loss: 12294.9600 - val_mse: 12294.9600\n",
      "Epoch 850/1000\n",
      "135/135 [==============================] - 0s 163us/sample - loss: 454.7943 - mse: 454.7943 - val_loss: 12339.4972 - val_mse: 12339.4971\n",
      "Epoch 851/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 454.5674 - mse: 454.5674 - val_loss: 12605.8111 - val_mse: 12605.8105\n",
      "Epoch 852/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 462.8042 - mse: 462.8041 - val_loss: 12463.6866 - val_mse: 12463.6865\n",
      "Epoch 853/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 452.0000 - mse: 451.9999 - val_loss: 12545.7794 - val_mse: 12545.7793\n",
      "Epoch 854/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 461.9800 - mse: 461.9799 - val_loss: 12420.9113 - val_mse: 12420.9121\n",
      "Epoch 855/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 452.7548 - mse: 452.7548 - val_loss: 12638.2702 - val_mse: 12638.2705\n",
      "Epoch 856/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 451.1006 - mse: 451.1007 - val_loss: 12692.5432 - val_mse: 12692.5430\n",
      "Epoch 857/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 452.0336 - mse: 452.0336 - val_loss: 12546.3672 - val_mse: 12546.3672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 858/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 445.3674 - mse: 445.3674 - val_loss: 12505.8773 - val_mse: 12505.8770\n",
      "Epoch 859/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 445.7794 - mse: 445.7794 - val_loss: 12581.6668 - val_mse: 12581.6670\n",
      "Epoch 860/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 449.6416 - mse: 449.6415 - val_loss: 12430.2454 - val_mse: 12430.2451\n",
      "Epoch 861/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 434.4758 - mse: 434.4758 - val_loss: 12641.4550 - val_mse: 12641.4551\n",
      "Epoch 862/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 453.5969 - mse: 453.5969 - val_loss: 12439.6682 - val_mse: 12439.6680\n",
      "Epoch 863/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 432.5941 - mse: 432.5941 - val_loss: 12390.3617 - val_mse: 12390.3623\n",
      "Epoch 864/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 440.0145 - mse: 440.0145 - val_loss: 12473.3874 - val_mse: 12473.3877\n",
      "Epoch 865/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 439.7611 - mse: 439.7612 - val_loss: 12404.4122 - val_mse: 12404.4121\n",
      "Epoch 866/1000\n",
      "135/135 [==============================] - 0s 163us/sample - loss: 438.1550 - mse: 438.1549 - val_loss: 12348.5418 - val_mse: 12348.5420\n",
      "Epoch 867/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 439.4991 - mse: 439.4991 - val_loss: 12597.8231 - val_mse: 12597.8232\n",
      "Epoch 868/1000\n",
      "135/135 [==============================] - 0s 163us/sample - loss: 431.7878 - mse: 431.7878 - val_loss: 12293.2578 - val_mse: 12293.2578\n",
      "Epoch 869/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 434.3444 - mse: 434.3444 - val_loss: 12293.3768 - val_mse: 12293.3770\n",
      "Epoch 870/1000\n",
      "135/135 [==============================] - 0s 163us/sample - loss: 436.5146 - mse: 436.5146 - val_loss: 12140.2459 - val_mse: 12140.2461\n",
      "Epoch 871/1000\n",
      "135/135 [==============================] - 0s 163us/sample - loss: 437.8260 - mse: 437.8260 - val_loss: 12296.3529 - val_mse: 12296.3525\n",
      "Epoch 872/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 432.3755 - mse: 432.3755 - val_loss: 12460.2431 - val_mse: 12460.2422\n",
      "Epoch 873/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 425.6478 - mse: 425.6478 - val_loss: 12568.8189 - val_mse: 12568.8193\n",
      "Epoch 874/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 427.3983 - mse: 427.3983 - val_loss: 12506.9389 - val_mse: 12506.9395\n",
      "Epoch 875/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 426.1069 - mse: 426.1069 - val_loss: 12530.7900 - val_mse: 12530.7900\n",
      "Epoch 876/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 435.2377 - mse: 435.2377 - val_loss: 12308.8185 - val_mse: 12308.8184\n",
      "Epoch 877/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 427.4024 - mse: 427.4025 - val_loss: 12207.3842 - val_mse: 12207.3838\n",
      "Epoch 878/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 430.0798 - mse: 430.0798 - val_loss: 12454.2996 - val_mse: 12454.2998\n",
      "Epoch 879/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 421.6951 - mse: 421.6951 - val_loss: 12495.5938 - val_mse: 12495.5938\n",
      "Epoch 880/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 432.6770 - mse: 432.6770 - val_loss: 12371.9628 - val_mse: 12371.9629\n",
      "Epoch 881/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 420.0425 - mse: 420.0425 - val_loss: 12451.0565 - val_mse: 12451.0566\n",
      "Epoch 882/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 418.9717 - mse: 418.9717 - val_loss: 12516.1406 - val_mse: 12516.1406\n",
      "Epoch 883/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 414.8652 - mse: 414.8652 - val_loss: 12371.9949 - val_mse: 12371.9941\n",
      "Epoch 884/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 421.4616 - mse: 421.4616 - val_loss: 12571.3778 - val_mse: 12571.3779\n",
      "Epoch 885/1000\n",
      "135/135 [==============================] - 0s 258us/sample - loss: 419.4234 - mse: 419.4234 - val_loss: 12543.4789 - val_mse: 12543.4785\n",
      "Epoch 886/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 412.3667 - mse: 412.3667 - val_loss: 12599.9775 - val_mse: 12599.9775\n",
      "Epoch 887/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 420.7403 - mse: 420.7403 - val_loss: 12757.9968 - val_mse: 12757.9961\n",
      "Epoch 888/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 419.4433 - mse: 419.4433 - val_loss: 12628.3451 - val_mse: 12628.3457\n",
      "Epoch 889/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 421.8367 - mse: 421.8367 - val_loss: 12640.2688 - val_mse: 12640.2686\n",
      "Epoch 890/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 419.2978 - mse: 419.2977 - val_loss: 12637.5322 - val_mse: 12637.5322\n",
      "Epoch 891/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 410.7606 - mse: 410.7606 - val_loss: 12646.8231 - val_mse: 12646.8232\n",
      "Epoch 892/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 413.6406 - mse: 413.6406 - val_loss: 12457.4026 - val_mse: 12457.4023\n",
      "Epoch 893/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 407.5625 - mse: 407.5625 - val_loss: 12488.7445 - val_mse: 12488.7441\n",
      "Epoch 894/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 409.4348 - mse: 409.4348 - val_loss: 12504.0533 - val_mse: 12504.0537\n",
      "Epoch 895/1000\n",
      "135/135 [==============================] - 0s 163us/sample - loss: 406.2284 - mse: 406.2285 - val_loss: 12245.1774 - val_mse: 12245.1777\n",
      "Epoch 896/1000\n",
      "135/135 [==============================] - 0s 163us/sample - loss: 407.9614 - mse: 407.9614 - val_loss: 12364.3805 - val_mse: 12364.3809\n",
      "Epoch 897/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 406.7794 - mse: 406.7794 - val_loss: 12506.5308 - val_mse: 12506.5312\n",
      "Epoch 898/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 402.1475 - mse: 402.1476 - val_loss: 12215.9370 - val_mse: 12215.9375\n",
      "Epoch 899/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 403.4150 - mse: 403.4150 - val_loss: 12310.1043 - val_mse: 12310.1045\n",
      "Epoch 900/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 402.4783 - mse: 402.4783 - val_loss: 12566.5708 - val_mse: 12566.5703\n",
      "Epoch 901/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 407.4011 - mse: 407.4011 - val_loss: 12488.4554 - val_mse: 12488.4561\n",
      "Epoch 902/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 404.6874 - mse: 404.6874 - val_loss: 12206.1558 - val_mse: 12206.1562\n",
      "Epoch 903/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 399.8225 - mse: 399.8225 - val_loss: 12281.1774 - val_mse: 12281.1777\n",
      "Epoch 904/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 407.3760 - mse: 407.3759 - val_loss: 12445.6700 - val_mse: 12445.6699\n",
      "Epoch 905/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 392.7738 - mse: 392.7738 - val_loss: 12408.7027 - val_mse: 12408.7021\n",
      "Epoch 906/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 393.2082 - mse: 393.2083 - val_loss: 12444.4421 - val_mse: 12444.4424\n",
      "Epoch 907/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 398.7555 - mse: 398.7555 - val_loss: 12480.9421 - val_mse: 12480.9424\n",
      "Epoch 908/1000\n",
      "135/135 [==============================] - 0s 200us/sample - loss: 400.9964 - mse: 400.9964 - val_loss: 12459.7307 - val_mse: 12459.7305\n",
      "Epoch 909/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 396.3792 - mse: 396.3792 - val_loss: 12544.3557 - val_mse: 12544.3555\n",
      "Epoch 910/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 393.3027 - mse: 393.3027 - val_loss: 12421.9150 - val_mse: 12421.9150\n",
      "Epoch 911/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 394.0954 - mse: 394.0954 - val_loss: 12580.3474 - val_mse: 12580.3477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 912/1000\n",
      "135/135 [==============================] - 0s 184us/sample - loss: 406.4908 - mse: 406.4908 - val_loss: 12558.4600 - val_mse: 12558.4600\n",
      "Epoch 913/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 387.1955 - mse: 387.1955 - val_loss: 12471.6843 - val_mse: 12471.6836\n",
      "Epoch 914/1000\n",
      "135/135 [==============================] - 0s 163us/sample - loss: 400.2078 - mse: 400.2078 - val_loss: 12498.3768 - val_mse: 12498.3770\n",
      "Epoch 915/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 401.0312 - mse: 401.0312 - val_loss: 12663.7472 - val_mse: 12663.7471\n",
      "Epoch 916/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 390.7273 - mse: 390.7273 - val_loss: 12625.1094 - val_mse: 12625.1094\n",
      "Epoch 917/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 394.5145 - mse: 394.5145 - val_loss: 12556.4095 - val_mse: 12556.4102\n",
      "Epoch 918/1000\n",
      "135/135 [==============================] - 0s 236us/sample - loss: 385.4327 - mse: 385.4328 - val_loss: 12609.7863 - val_mse: 12609.7871\n",
      "Epoch 919/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 388.0671 - mse: 388.0671 - val_loss: 12589.9439 - val_mse: 12589.9443\n",
      "Epoch 920/1000\n",
      "135/135 [==============================] - 0s 193us/sample - loss: 381.5182 - mse: 381.5181 - val_loss: 12700.7923 - val_mse: 12700.7920\n",
      "Epoch 921/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 385.7546 - mse: 385.7546 - val_loss: 12810.1301 - val_mse: 12810.1309\n",
      "Epoch 922/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 395.8754 - mse: 395.8754 - val_loss: 12776.8764 - val_mse: 12776.8770\n",
      "Epoch 923/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 384.4391 - mse: 384.4391 - val_loss: 12669.5703 - val_mse: 12669.5703\n",
      "Epoch 924/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 383.8545 - mse: 383.8546 - val_loss: 12667.4449 - val_mse: 12667.4453\n",
      "Epoch 925/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 387.0254 - mse: 387.0254 - val_loss: 12542.0037 - val_mse: 12542.0039\n",
      "Epoch 926/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 381.3967 - mse: 381.3967 - val_loss: 12549.3644 - val_mse: 12549.3643\n",
      "Epoch 927/1000\n",
      "135/135 [==============================] - 0s 178us/sample - loss: 377.1211 - mse: 377.1211 - val_loss: 12334.9830 - val_mse: 12334.9834\n",
      "Epoch 928/1000\n",
      "135/135 [==============================] - 0s 184us/sample - loss: 382.4731 - mse: 382.4731 - val_loss: 12495.6549 - val_mse: 12495.6543\n",
      "Epoch 929/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 388.8444 - mse: 388.8444 - val_loss: 12516.5032 - val_mse: 12516.5039\n",
      "Epoch 930/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 370.2728 - mse: 370.2728 - val_loss: 12437.6213 - val_mse: 12437.6211\n",
      "Epoch 931/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 368.2060 - mse: 368.2060 - val_loss: 12495.2224 - val_mse: 12495.2227\n",
      "Epoch 932/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 375.6349 - mse: 375.6349 - val_loss: 12543.4632 - val_mse: 12543.4629\n",
      "Epoch 933/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 371.1947 - mse: 371.1947 - val_loss: 12432.9219 - val_mse: 12432.9219\n",
      "Epoch 934/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 373.0099 - mse: 373.0099 - val_loss: 12535.2509 - val_mse: 12535.2510\n",
      "Epoch 935/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 375.2244 - mse: 375.2245 - val_loss: 12491.4802 - val_mse: 12491.4795\n",
      "Epoch 936/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 371.3113 - mse: 371.3113 - val_loss: 12427.3915 - val_mse: 12427.3916\n",
      "Epoch 937/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 369.7580 - mse: 369.7580 - val_loss: 12551.5170 - val_mse: 12551.5166\n",
      "Epoch 938/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 367.6800 - mse: 367.6800 - val_loss: 12363.6903 - val_mse: 12363.6904\n",
      "Epoch 939/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 381.1328 - mse: 381.1328 - val_loss: 12526.5749 - val_mse: 12526.5752\n",
      "Epoch 940/1000\n",
      "135/135 [==============================] - 0s 200us/sample - loss: 375.6450 - mse: 375.6451 - val_loss: 12587.2629 - val_mse: 12587.2627\n",
      "Epoch 941/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 370.7214 - mse: 370.7214 - val_loss: 12481.4338 - val_mse: 12481.4336\n",
      "Epoch 942/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 365.3753 - mse: 365.3753 - val_loss: 12647.6549 - val_mse: 12647.6543\n",
      "Epoch 943/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 364.8588 - mse: 364.8588 - val_loss: 12509.7532 - val_mse: 12509.7539\n",
      "Epoch 944/1000\n",
      "135/135 [==============================] - 0s 222us/sample - loss: 369.6092 - mse: 369.6091 - val_loss: 12541.0234 - val_mse: 12541.0234\n",
      "Epoch 945/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 374.3862 - mse: 374.3862 - val_loss: 12534.0519 - val_mse: 12534.0518\n",
      "Epoch 946/1000\n",
      "135/135 [==============================] - 0s 214us/sample - loss: 358.1457 - mse: 358.1457 - val_loss: 12371.1636 - val_mse: 12371.1641\n",
      "Epoch 947/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 354.1366 - mse: 354.1366 - val_loss: 12384.7877 - val_mse: 12384.7881\n",
      "Epoch 948/1000\n",
      "135/135 [==============================] - 0s 222us/sample - loss: 371.7720 - mse: 371.7720 - val_loss: 12256.6820 - val_mse: 12256.6816\n",
      "Epoch 949/1000\n",
      "135/135 [==============================] - 0s 229us/sample - loss: 357.8629 - mse: 357.8629 - val_loss: 12379.9182 - val_mse: 12379.9180\n",
      "Epoch 950/1000\n",
      "135/135 [==============================] - 0s 222us/sample - loss: 367.9315 - mse: 367.9315 - val_loss: 12196.6296 - val_mse: 12196.6299\n",
      "Epoch 951/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 369.3832 - mse: 369.3831 - val_loss: 12303.4614 - val_mse: 12303.4609\n",
      "Epoch 952/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 357.2864 - mse: 357.2864 - val_loss: 12287.7482 - val_mse: 12287.7480\n",
      "Epoch 953/1000\n",
      "135/135 [==============================] - 0s 214us/sample - loss: 359.9759 - mse: 359.9759 - val_loss: 12361.2036 - val_mse: 12361.2041\n",
      "Epoch 954/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 361.5653 - mse: 361.5653 - val_loss: 12349.9591 - val_mse: 12349.9600\n",
      "Epoch 955/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 350.7744 - mse: 350.7744 - val_loss: 12309.1195 - val_mse: 12309.1191\n",
      "Epoch 956/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 357.3499 - mse: 357.3499 - val_loss: 12149.0487 - val_mse: 12149.0488\n",
      "Epoch 957/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 358.7246 - mse: 358.7246 - val_loss: 12308.2955 - val_mse: 12308.2959\n",
      "Epoch 958/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 351.2033 - mse: 351.2033 - val_loss: 12486.8948 - val_mse: 12486.8955\n",
      "Epoch 959/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 352.4744 - mse: 352.4744 - val_loss: 12400.1448 - val_mse: 12400.1455\n",
      "Epoch 960/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 346.6481 - mse: 346.6481 - val_loss: 12567.5188 - val_mse: 12567.5186\n",
      "Epoch 961/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 354.1009 - mse: 354.1010 - val_loss: 12541.3791 - val_mse: 12541.3789\n",
      "Epoch 962/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 354.9751 - mse: 354.9750 - val_loss: 12664.6356 - val_mse: 12664.6357\n",
      "Epoch 963/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 348.4723 - mse: 348.4724 - val_loss: 12679.3943 - val_mse: 12679.3945\n",
      "Epoch 964/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 348.5540 - mse: 348.5540 - val_loss: 12550.9439 - val_mse: 12550.9443\n",
      "Epoch 965/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 351.3934 - mse: 351.3934 - val_loss: 12449.8608 - val_mse: 12449.8604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 966/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 355.5768 - mse: 355.5768 - val_loss: 12491.3736 - val_mse: 12491.3730\n",
      "Epoch 967/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 341.4030 - mse: 341.4030 - val_loss: 12614.6631 - val_mse: 12614.6641\n",
      "Epoch 968/1000\n",
      "135/135 [==============================] - 0s 163us/sample - loss: 344.2222 - mse: 344.2222 - val_loss: 12594.7266 - val_mse: 12594.7266\n",
      "Epoch 969/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 349.9861 - mse: 349.9861 - val_loss: 12292.0951 - val_mse: 12292.0957\n",
      "Epoch 970/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 342.3883 - mse: 342.3883 - val_loss: 12473.2799 - val_mse: 12473.2793\n",
      "Epoch 971/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 338.9831 - mse: 338.9831 - val_loss: 12480.3226 - val_mse: 12480.3223\n",
      "Epoch 972/1000\n",
      "135/135 [==============================] - 0s 163us/sample - loss: 340.2946 - mse: 340.2946 - val_loss: 12480.6682 - val_mse: 12480.6680\n",
      "Epoch 973/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 342.8127 - mse: 342.8127 - val_loss: 12603.7964 - val_mse: 12603.7959\n",
      "Epoch 974/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 336.8548 - mse: 336.8548 - val_loss: 12460.9030 - val_mse: 12460.9023\n",
      "Epoch 975/1000\n",
      "135/135 [==============================] - 0s 163us/sample - loss: 339.0957 - mse: 339.0957 - val_loss: 12536.4435 - val_mse: 12536.4434\n",
      "Epoch 976/1000\n",
      "135/135 [==============================] - 0s 163us/sample - loss: 336.6447 - mse: 336.6447 - val_loss: 12464.8116 - val_mse: 12464.8115\n",
      "Epoch 977/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 329.2229 - mse: 329.2229 - val_loss: 12589.7762 - val_mse: 12589.7754\n",
      "Epoch 978/1000\n",
      "135/135 [==============================] - 0s 148us/sample - loss: 344.4031 - mse: 344.4031 - val_loss: 12598.1369 - val_mse: 12598.1367\n",
      "Epoch 979/1000\n",
      "135/135 [==============================] - 0s 166us/sample - loss: 331.6795 - mse: 331.6795 - val_loss: 12479.1530 - val_mse: 12479.1523\n",
      "Epoch 980/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 343.3798 - mse: 343.3798 - val_loss: 12685.3107 - val_mse: 12685.3105\n",
      "Epoch 981/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 332.1500 - mse: 332.1500 - val_loss: 12608.4141 - val_mse: 12608.4141\n",
      "Epoch 982/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 337.2090 - mse: 337.2090 - val_loss: 12540.7904 - val_mse: 12540.7900\n",
      "Epoch 983/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 326.8424 - mse: 326.8423 - val_loss: 12416.5607 - val_mse: 12416.5605\n",
      "Epoch 984/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 327.5404 - mse: 327.5403 - val_loss: 12343.8047 - val_mse: 12343.8047\n",
      "Epoch 985/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 333.2890 - mse: 333.2890 - val_loss: 12409.8938 - val_mse: 12409.8936\n",
      "Epoch 986/1000\n",
      "135/135 [==============================] - 0s 185us/sample - loss: 328.5234 - mse: 328.5234 - val_loss: 12314.0717 - val_mse: 12314.0713\n",
      "Epoch 987/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 325.0443 - mse: 325.0443 - val_loss: 12591.1002 - val_mse: 12591.1006\n",
      "Epoch 988/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 324.8967 - mse: 324.8967 - val_loss: 12575.9164 - val_mse: 12575.9160\n",
      "Epoch 989/1000\n",
      "135/135 [==============================] - 0s 177us/sample - loss: 321.4716 - mse: 321.4716 - val_loss: 12467.6769 - val_mse: 12467.6768\n",
      "Epoch 990/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 324.4845 - mse: 324.4845 - val_loss: 12411.5184 - val_mse: 12411.5186\n",
      "Epoch 991/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 318.5448 - mse: 318.5448 - val_loss: 12569.1296 - val_mse: 12569.1299\n",
      "Epoch 992/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 327.3902 - mse: 327.3902 - val_loss: 12632.0708 - val_mse: 12632.0703\n",
      "Epoch 993/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 326.0648 - mse: 326.0648 - val_loss: 12247.1029 - val_mse: 12247.1025\n",
      "Epoch 994/1000\n",
      "135/135 [==============================] - 0s 192us/sample - loss: 321.7448 - mse: 321.7448 - val_loss: 12321.3277 - val_mse: 12321.3271\n",
      "Epoch 995/1000\n",
      "135/135 [==============================] - 0s 214us/sample - loss: 320.7276 - mse: 320.7275 - val_loss: 12294.5041 - val_mse: 12294.5039\n",
      "Epoch 996/1000\n",
      "135/135 [==============================] - 0s 214us/sample - loss: 328.0486 - mse: 328.0486 - val_loss: 12197.4858 - val_mse: 12197.4854\n",
      "Epoch 997/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 316.7872 - mse: 316.7872 - val_loss: 12437.8313 - val_mse: 12437.8311\n",
      "Epoch 998/1000\n",
      "135/135 [==============================] - 0s 170us/sample - loss: 321.6546 - mse: 321.6546 - val_loss: 12419.5487 - val_mse: 12419.5488\n",
      "Epoch 999/1000\n",
      "135/135 [==============================] - 0s 207us/sample - loss: 315.7511 - mse: 315.7511 - val_loss: 12498.6581 - val_mse: 12498.6582\n",
      "Epoch 1000/1000\n",
      "135/135 [==============================] - 0s 199us/sample - loss: 321.5422 - mse: 321.5422 - val_loss: 12538.2698 - val_mse: 12538.2705\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23e7b2cc898>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_shape=[len(normed_X.keys())]))  # shape [1:] : -1  \n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Dense(64))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Dense(1))\n",
    "\n",
    "optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "\n",
    "model.compile(loss=\"mse\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=['mse'])\n",
    "\n",
    "model.fit(normed_X, y, epochs=1000, validation_split=0.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
